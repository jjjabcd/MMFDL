{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import networkx as nx\n",
    "from mmfdl.util.data_gen_modify import make_variable_one\n",
    "from mmfdl.util.utils import formDataset_Single\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom):\n",
    "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
    "        ['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na','Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb',\n",
    "         'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H','Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr',\n",
    "         'Cr', 'Pt', 'Hg', 'Pb', 'Unknown']) +\n",
    "        one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "        one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "        one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "        [atom.GetIsAromatic()])\n",
    "\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(f\"input {x} not in allowable set{allowable_set}:\")\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def smile_to_graph(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol is None:\n",
    "        return None, None, None\n",
    "    \n",
    "    c_size = mol.GetNumAtoms()\n",
    "    \n",
    "    features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        feature = atom_features(atom)\n",
    "        features.append(feature / sum(feature))\n",
    "\n",
    "    edges = []\n",
    "    for bond in mol.GetBonds():\n",
    "        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    g = nx.Graph(edges).to_directed()\n",
    "    edge_index = []\n",
    "    for e1, e2 in g.edges:\n",
    "        edge_index.append([e1, e2])\n",
    "        \n",
    "    return c_size, features, edge_index\n",
    "\n",
    "def process_csv_to_pt(csv_path, vocab_path, results_dir, dataset_name, \n",
    "                      input_col='SMILES', target_col='Ssel', max_smiles_len=44, ecfp_bits=2048):\n",
    "    \"\"\"\n",
    "    Generate .pt from csv\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    csv_path : str\n",
    "    vocab_path : str\n",
    "    results_dir : str\n",
    "    dataset_name : str\n",
    "    input_col : str\n",
    "    target_col : str\n",
    "    max_smiles_len : int\n",
    "    ecfp_bits : int\n",
    "    \"\"\"\n",
    "    print(f'\\nProcessing {csv_path}...')\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    if input_col not in df.columns:\n",
    "        raise ValueError(f\"Input column '{input_col}' not found in CSV. Available columns: {df.columns.tolist()}\")\n",
    "    if target_col not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target_col}' not found in CSV. Available columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    smiles_list = df[input_col].dropna().tolist()\n",
    "    labels = df[target_col].dropna().tolist()\n",
    "    \n",
    "    min_len = min(len(smiles_list), len(labels))\n",
    "    smiles_list = smiles_list[:min_len]\n",
    "    labels = labels[:min_len]\n",
    "    \n",
    "    print(f'  Found {len(smiles_list)} samples')\n",
    "    \n",
    "    with open(vocab_path, 'rb') as f:\n",
    "        smilesVoc = pickle.load(f)\n",
    "    \n",
    "    encoded_smi_list = []\n",
    "    ecfp_list = []\n",
    "    labels_list = []\n",
    "    smile_graph_dict = {}\n",
    "    \n",
    "    valid_count = 0\n",
    "    for idx, (smi, label) in enumerate(zip(smiles_list, labels)):\n",
    "        if pd.isna(smi) or pd.isna(label):\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # SMILES encoding\n",
    "            encoded_smi = make_variable_one(smi, smilesVoc, max_smiles_len)\n",
    "            \n",
    "            # Generate ECFP\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            if mol is None:\n",
    "                continue\n",
    "            if mol.HasSubstructMatch(Chem.MolFromSmarts(\"[H]\")):\n",
    "                mol = Chem.RemoveHs(mol)\n",
    "            ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=ecfp_bits)\n",
    "            ecfp_array = np.array(ecfp, dtype=np.float32)\n",
    "            \n",
    "            # Generate Graph\n",
    "            c_size, features, edge_index = smile_to_graph(smi)\n",
    "            if edge_index == [] or features is None:\n",
    "                continue\n",
    "            \n",
    "            encoded_smi_list.append(encoded_smi)\n",
    "            ecfp_list.append(ecfp_array.tolist())\n",
    "            labels_list.append(float(label))\n",
    "            smile_graph_dict[valid_count] = (c_size, features, edge_index)\n",
    "            valid_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'  Error processing SMILES {idx}: {smi}, error: {e}')\n",
    "            continue\n",
    "        \n",
    "    same = len(smiles_list) == valid_count\n",
    "    print(same)\n",
    "    \n",
    "    dataset = formDataset_Single(\n",
    "        root=results_dir,\n",
    "        dataset=dataset_name,\n",
    "        encodedSmi=encoded_smi_list,\n",
    "        ecfp=ecfp_list,\n",
    "        y=labels_list,\n",
    "        smile_graph=smile_graph_dict\n",
    "    )\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'selectivity'\n",
    "task_name = 'Ki'\n",
    "vocab_path = f'./data/{dataset_name}/{task_name}/smiles_char_dict.pkl'\n",
    "\n",
    "with open(vocab_path, 'rb') as f:\n",
    "    smilesVoc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing Fold 1\n",
      "============================================================\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold1/selectivity_train.csv...\n",
      "  Found 1313 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold1/selectivity_val.csv...\n",
      "  Found 146 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold1/selectivity_test.csv...\n",
      "  Found 365 samples\n",
      "True\n",
      "\n",
      "Fold 1 completed!\n",
      "Results saved to: ./data/selectivity/Ki/fold1\n",
      "\n",
      "============================================================\n",
      "Processing Fold 2\n",
      "============================================================\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold2/selectivity_train.csv...\n",
      "  Found 1313 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold2/selectivity_val.csv...\n",
      "  Found 146 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold2/selectivity_test.csv...\n",
      "  Found 365 samples\n",
      "True\n",
      "\n",
      "Fold 2 completed!\n",
      "Results saved to: ./data/selectivity/Ki/fold2\n",
      "\n",
      "============================================================\n",
      "Processing Fold 3\n",
      "============================================================\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold3/selectivity_train.csv...\n",
      "  Found 1313 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold3/selectivity_val.csv...\n",
      "  Found 146 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold3/selectivity_test.csv...\n",
      "  Found 365 samples\n",
      "True\n",
      "\n",
      "Fold 3 completed!\n",
      "Results saved to: ./data/selectivity/Ki/fold3\n",
      "\n",
      "============================================================\n",
      "Processing Fold 4\n",
      "============================================================\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold4/selectivity_train.csv...\n",
      "  Found 1313 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold4/selectivity_val.csv...\n",
      "  Found 146 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold4/selectivity_test.csv...\n",
      "  Found 365 samples\n",
      "True\n",
      "\n",
      "Fold 4 completed!\n",
      "Results saved to: ./data/selectivity/Ki/fold4\n",
      "\n",
      "============================================================\n",
      "Processing Fold 5\n",
      "============================================================\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold5/selectivity_train.csv...\n",
      "  Found 1314 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold5/selectivity_val.csv...\n",
      "  Found 146 samples\n",
      "True\n",
      "\n",
      "Processing /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold5/selectivity_test.csv...\n",
      "  Found 364 samples\n",
      "True\n",
      "\n",
      "Fold 5 completed!\n",
      "Results saved to: ./data/selectivity/Ki/fold5\n"
     ]
    }
   ],
   "source": [
    "start_fold_num = 1\n",
    "end_fold_num = 5\n",
    "\n",
    "for fold_num in range(start_fold_num, end_fold_num + 1):\n",
    "    input_dir = f'/home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Ki/fold{fold_num}'\n",
    "    results_dir = f'./data/{dataset_name}/{task_name}/fold{fold_num}'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # input file path\n",
    "    train_csv = f'{input_dir}/{dataset_name}_train.csv'\n",
    "    val_csv = f'{input_dir}/{dataset_name}_val.csv'\n",
    "    test_csv = f'{input_dir}/{dataset_name}_test.csv'\n",
    "\n",
    "    # Results file path\n",
    "    train_pt = f'{results_dir}/{dataset_name}_train.pt'\n",
    "    val_pt = f'{results_dir}/{dataset_name}_val.pt'\n",
    "    test_pt = f'{results_dir}/{dataset_name}_test.pt'\n",
    "\n",
    "    # Generate Train, Validation, Test\n",
    "    print('\\n' + '=' * 60)\n",
    "    print(f'Processing Fold {fold_num}')\n",
    "    print('=' * 60)\n",
    "\n",
    "    train_dataset = process_csv_to_pt(\n",
    "        csv_path=train_csv,\n",
    "        vocab_path=vocab_path,\n",
    "        results_dir=results_dir,\n",
    "        dataset_name=f'{dataset_name}_train',\n",
    "        input_col='SMILES',\n",
    "        target_col='Ssel',\n",
    "        ecfp_bits=2048\n",
    "    )\n",
    "\n",
    "    val_dataset = process_csv_to_pt(\n",
    "        csv_path=val_csv,\n",
    "        vocab_path=vocab_path,\n",
    "        results_dir=results_dir,\n",
    "        dataset_name=f'{dataset_name}_val',\n",
    "        input_col='SMILES',\n",
    "        target_col='Ssel',\n",
    "        ecfp_bits=2048\n",
    "    )\n",
    "\n",
    "    test_dataset = process_csv_to_pt(\n",
    "        csv_path=test_csv,\n",
    "        vocab_path=vocab_path,\n",
    "        results_dir=results_dir,\n",
    "        dataset_name=f'{dataset_name}_test',\n",
    "        input_col='SMILES',\n",
    "        target_col='Ssel',\n",
    "        ecfp_bits=2048\n",
    "    )\n",
    "\n",
    "    print(f'\\nFold {fold_num} completed!')\n",
    "    print(f'Results saved to: {results_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
