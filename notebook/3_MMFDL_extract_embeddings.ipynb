{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7dd29ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from mmfdl.util.utils_smiecfp import getInput_mask\n",
    "from mmfdl.util.utils import formDataset_Single\n",
    "from mmfdl.model.model_combination import comModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "951001e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights_from_csv(weight_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Load fusion weights from csv file.\n",
    "\n",
    "    Args:\n",
    "        weight_path (str): Path to weight csv with columns [Key, Value].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: (3,) weights in order (1,2,3).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(weight_path)\n",
    "    weight_dict = dict(zip(df[\"Key\"], df[\"Value\"]))\n",
    "    w = np.array([weight_dict[1], weight_dict[2], weight_dict[3]], dtype=np.float32)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696ba0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings_from_pt(\n",
    "    model: torch.nn.Module,\n",
    "    loader: DataLoader,\n",
    "    weights: np.ndarray,\n",
    "    device: torch.device,\n",
    ") -> Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "    \"\"\"\n",
    "    Extract unified embeddings from a DataLoader created from formDataset_Single (.pt).\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained comModel with get_embeddings().\n",
    "        loader (DataLoader): DataLoader over .pt dataset.\n",
    "        weights (np.ndarray): (3,) fusion weights.\n",
    "        device (torch.device): cuda/cpu.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray, List[str]]:\n",
    "            embeddings: (N, D)\n",
    "            labels: (N,)\n",
    "            smiles: list of SMILES strings (if present in batch, else empty strings)\n",
    "    \"\"\"\n",
    "    w = np.asarray(weights, dtype=np.float32)\n",
    "    if w.shape != (3,):\n",
    "        raise ValueError(f\"weights must be (3,), got {w.shape}\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    all_emb: List[np.ndarray] = []\n",
    "    all_y: List[np.ndarray] = []\n",
    "    all_smiles: List[str] = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            # ------------------------------------------------------\n",
    "            # NOTE: This assumes your .pt data object has:\n",
    "            #   data.smi, data.ep, data.x, data.edge_index, data.batch, data.y\n",
    "            # and optionally data.SMILES or data.smiles (string list)\n",
    "            # ------------------------------------------------------\n",
    "            encodedSmi = torch.as_tensor(data.smi, dtype=torch.long, device=device)  # (B, L)\n",
    "            smi_mask_np = getInput_mask(encodedSmi.cpu().numpy())                    # (B, L)\n",
    "            encodedSmi_mask = torch.as_tensor(smi_mask_np, dtype=torch.long, device=device)\n",
    "\n",
    "            ecfp = torch.as_tensor(data.ep, dtype=torch.float32, device=device)\n",
    "            # Ensure GRU input shape is (B, T, F)\n",
    "            if ecfp.dim() == 2:\n",
    "                ecfp = ecfp.unsqueeze(1)  # (B, 1, 2048)\n",
    "\n",
    "            x = data.x.to(device)\n",
    "            edge_index = data.edge_index.to(device)\n",
    "            batch = data.batch.to(device)\n",
    "\n",
    "            y = data.y.view(-1).detach().cpu().numpy().astype(np.float32)\n",
    "\n",
    "            smi_emb, ep_emb, gc_emb = model.get_embeddings(\n",
    "                encodedSmi, encodedSmi_mask, ecfp, x, edge_index, batch\n",
    "            )\n",
    "\n",
    "            smi_vec = smi_emb.detach().cpu().numpy().astype(np.float32)  # (B, hidden_dim)\n",
    "            ep_vec = ep_emb.detach().cpu().numpy().astype(np.float32)     # (B, output_dim)\n",
    "            gc_vec = gc_emb.detach().cpu().numpy().astype(np.float32)     # (B, 2*num_features_x)\n",
    "\n",
    "            fused = np.concatenate([w[0] * smi_vec, w[1] * ep_vec, w[2] * gc_vec], axis=1)  # (B, D)\n",
    "            all_emb.append(fused)\n",
    "            all_y.append(y)\n",
    "\n",
    "            # SMILES string (optional)\n",
    "            if hasattr(data, \"SMILES\"):\n",
    "                # PyG Batch may store as list\n",
    "                all_smiles.extend(list(data.SMILES))\n",
    "            elif hasattr(data, \"smiles\"):\n",
    "                all_smiles.extend(list(data.smiles))\n",
    "            else:\n",
    "                all_smiles.extend([\"\"] * fused.shape[0])\n",
    "\n",
    "    embeddings = np.vstack(all_emb) if len(all_emb) > 0 else np.zeros((0, 0), dtype=np.float32)\n",
    "    labels = np.concatenate(all_y) if len(all_y) > 0 else np.zeros((0,), dtype=np.float32)\n",
    "    return embeddings, labels, all_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1efb32a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] device=cuda:0\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# Main\n",
    "# =============================\n",
    "dataset_name = \"selectivity\"\n",
    "task_name = \"Ki\"\n",
    "START_FOLD = 1\n",
    "END_FOLD = 5\n",
    "\n",
    "work_dir = \"/home/rlawlsgurjh/hdd/work/MMFDL\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[INFO] device={device}\")\n",
    "\n",
    "vocab_path = os.path.join(work_dir, \"data\", dataset_name, task_name, \"smiles_char_dict.pkl\")\n",
    "with open(vocab_path, \"rb\") as f:\n",
    "    smilesVoc = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f6fad4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "argsCom = {\n",
    "    \"num_features_smi\": len(smilesVoc),\n",
    "    \"num_features_ecfp\": 2048,\n",
    "    \"num_features_x\": 78,\n",
    "    \"dropout\": 0.1,\n",
    "    \"num_layer\": 2,\n",
    "    \"num_heads\": 2,\n",
    "    \"hidden_dim\": 256,\n",
    "    \"output_dim\": 128,\n",
    "    \"n_output\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d506a7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[Fold 1] PT-based embedding extraction\n",
      "================================================================================\n",
      "[INFO] weights=[0.56694883 0.35034388 0.08510989]\n",
      "[INFO] Extracting Train+Val embeddings from PT...\n",
      "[INFO] Train+Val embeddings: (1459, 540), labels: (1459,)\n",
      "[INFO] Extracting Test embeddings from PT...\n",
      "[INFO] Test embeddings: (365, 540), labels: (365,)\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold1/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold1/embeddings/te_embeddings.npy\n",
      "[Fold 1] Done.\n",
      "\n",
      "================================================================================\n",
      "[Fold 2] PT-based embedding extraction\n",
      "================================================================================\n",
      "[INFO] weights=[0.6294782  0.26747948 0.10409598]\n",
      "[INFO] Extracting Train+Val embeddings from PT...\n",
      "[INFO] Train+Val embeddings: (1459, 540), labels: (1459,)\n",
      "[INFO] Extracting Test embeddings from PT...\n",
      "[INFO] Test embeddings: (365, 540), labels: (365,)\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold2/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold2/embeddings/te_embeddings.npy\n",
      "[Fold 2] Done.\n",
      "\n",
      "================================================================================\n",
      "[Fold 3] PT-based embedding extraction\n",
      "================================================================================\n",
      "[INFO] weights=[0.6019824  0.32539174 0.07588837]\n",
      "[INFO] Extracting Train+Val embeddings from PT...\n",
      "[INFO] Train+Val embeddings: (1459, 540), labels: (1459,)\n",
      "[INFO] Extracting Test embeddings from PT...\n",
      "[INFO] Test embeddings: (365, 540), labels: (365,)\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold3/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold3/embeddings/te_embeddings.npy\n",
      "[Fold 3] Done.\n",
      "\n",
      "================================================================================\n",
      "[Fold 4] PT-based embedding extraction\n",
      "================================================================================\n",
      "[INFO] weights=[0.49203098 0.42199942 0.09284203]\n",
      "[INFO] Extracting Train+Val embeddings from PT...\n",
      "[INFO] Train+Val embeddings: (1459, 540), labels: (1459,)\n",
      "[INFO] Extracting Test embeddings from PT...\n",
      "[INFO] Test embeddings: (365, 540), labels: (365,)\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold4/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold4/embeddings/te_embeddings.npy\n",
      "[Fold 4] Done.\n",
      "\n",
      "================================================================================\n",
      "[Fold 5] PT-based embedding extraction\n",
      "================================================================================\n",
      "[INFO] weights=[0.5847384  0.3425488  0.07642845]\n",
      "[INFO] Extracting Train+Val embeddings from PT...\n",
      "[INFO] Train+Val embeddings: (1460, 540), labels: (1460,)\n",
      "[INFO] Extracting Test embeddings from PT...\n",
      "[INFO] Test embeddings: (364, 540), labels: (364,)\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold5/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved: /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Ki/fold5/embeddings/te_embeddings.npy\n",
      "[Fold 5] Done.\n"
     ]
    }
   ],
   "source": [
    "for fold_num in range(START_FOLD, END_FOLD + 1):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"[Fold {fold_num}] PT-based embedding extraction\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 1) Load trained model + weights\n",
    "    # -----------------------------------------\n",
    "    checkpoint_dir = os.path.join(work_dir, \"results\", \"SGD\", dataset_name, task_name, f\"fold{fold_num}\")\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, \"best_model.pt\")\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f\"[WARN] checkpoint not found: {checkpoint_path}\")\n",
    "        continue\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    best_epoch = int(checkpoint[\"epoch\"])\n",
    "\n",
    "    weight_path = os.path.join(\n",
    "        checkpoint_dir,\n",
    "        f\"{dataset_name}_{task_name}_fold{fold_num}_weight_epoch_{best_epoch}.csv\",\n",
    "    )\n",
    "    if not os.path.exists(weight_path):\n",
    "        print(f\"[WARN] weight file not found: {weight_path}\")\n",
    "        continue\n",
    "\n",
    "    weights = load_weights_from_csv(weight_path)\n",
    "    print(f\"[INFO] weights={weights}\")\n",
    "\n",
    "    model = comModel(argsCom).to(device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 2) Load .pt datasets (same as training)\n",
    "    # -----------------------------------------\n",
    "    pt_dir = os.path.join(work_dir, \"data\", dataset_name, task_name, f\"fold{fold_num}\")\n",
    "\n",
    "    train_pt = os.path.join(pt_dir, f\"{dataset_name}_train.pt\")\n",
    "    val_pt = os.path.join(pt_dir, f\"{dataset_name}_val.pt\")\n",
    "    test_pt = os.path.join(pt_dir, f\"{dataset_name}_test.pt\")\n",
    "\n",
    "    if not (os.path.exists(train_pt) and os.path.exists(val_pt) and os.path.exists(test_pt)):\n",
    "        print(f\"[WARN] missing pt files in: {pt_dir}\")\n",
    "        print(f\"  train_pt exists={os.path.exists(train_pt)}\")\n",
    "        print(f\"  val_pt   exists={os.path.exists(val_pt)}\")\n",
    "        print(f\"  test_pt  exists={os.path.exists(test_pt)}\")\n",
    "        continue\n",
    "\n",
    "    train_data = formDataset_Single(root=pt_dir, dataset=f\"{dataset_name}_train\")\n",
    "    val_data = formDataset_Single(root=pt_dir, dataset=f\"{dataset_name}_val\")\n",
    "    test_data = formDataset_Single(root=pt_dir, dataset=f\"{dataset_name}_test\")\n",
    "\n",
    "    # combine train+val (like your earlier script)\n",
    "    tr_val_data = list(train_data) + list(val_data)\n",
    "\n",
    "    # DataLoader (PyG dataset can be loaded with torch_geometric.loader.DataLoader ideally)\n",
    "    # If you already used torch.utils.data.DataLoader during training, keep it consistent.\n",
    "    tr_val_loader = DataLoader(tr_val_data, batch_size=1, shuffle=False)\n",
    "    test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 3) Extract embeddings\n",
    "    # -----------------------------------------\n",
    "    print(\"[INFO] Extracting Train+Val embeddings from PT...\")\n",
    "    emb_tr_val, y_tr_val, smiles_tr_val = extract_embeddings_from_pt(model, tr_val_loader, weights, device)\n",
    "    print(f\"[INFO] Train+Val embeddings: {emb_tr_val.shape}, labels: {y_tr_val.shape}\")\n",
    "\n",
    "    print(\"[INFO] Extracting Test embeddings from PT...\")\n",
    "    emb_te, y_te, smiles_te = extract_embeddings_from_pt(model, test_loader, weights, device)\n",
    "    print(f\"[INFO] Test embeddings: {emb_te.shape}, labels: {y_te.shape}\")\n",
    "\n",
    "    # -----------------------------------------\n",
    "    # 4) Save (npz)\n",
    "    # -----------------------------------------\n",
    "    out_dir = os.path.join(checkpoint_dir, \"embeddings\")\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    tr_val_path = os.path.join(out_dir, \"tr_val_embeddings.npy\")\n",
    "    te_path = os.path.join(out_dir, \"te_embeddings.npy\")\n",
    "\n",
    "    np.save(\n",
    "        tr_val_path,\n",
    "        {\n",
    "            \"embeddings\": emb_tr_val,\n",
    "            \"Ssel\": y_tr_val,\n",
    "            \"SMILES\": np.array(smiles_tr_val, dtype=object),\n",
    "        }\n",
    "    )\n",
    "    np.save(\n",
    "        te_path,\n",
    "        {\n",
    "            \"embeddings\": emb_te,\n",
    "            \"Ssel\": y_te,\n",
    "            \"SMILES\": np.array(smiles_te, dtype=object),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\"[INFO] Saved: {tr_val_path}\")\n",
    "    print(f\"[INFO] Saved: {te_path}\")\n",
    "    print(f\"[Fold {fold_num}] Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ebfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b07a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ac476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7b2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
