{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "503ba962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import networkx as nx\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric import data as DATA\n",
    "\n",
    "from mmfdl.util.data_gen_modify import make_variable_one\n",
    "from mmfdl.util.utils_smiecfp import getInput_mask\n",
    "from mmfdl.model.model_combination import comModel\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Helper functions (MMFDL_external_test.ipynb에서 가져옴)\n",
    "def one_of_k_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(f\"input {x} not in allowable set{allowable_set}:\")\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def atom_features(atom):\n",
    "    return np.array(one_of_k_encoding_unk(atom.GetSymbol(),\n",
    "        ['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na','Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb',\n",
    "         'Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H','Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr',\n",
    "         'Cr', 'Pt', 'Hg', 'Pb', 'Unknown']) +\n",
    "        one_of_k_encoding(atom.GetDegree(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "        one_of_k_encoding_unk(atom.GetTotalNumHs(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "        one_of_k_encoding_unk(atom.GetImplicitValence(), [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) +\n",
    "        [atom.GetIsAromatic()])\n",
    "\n",
    "def smile_to_graph(smile):\n",
    "    mol = Chem.MolFromSmiles(smile)\n",
    "    if mol is None:\n",
    "        return None, None, []\n",
    "    \n",
    "    c_size = mol.GetNumAtoms()\n",
    "    \n",
    "    features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        feature = atom_features(atom)\n",
    "        features.append(feature / sum(feature))\n",
    "    \n",
    "    edges = []\n",
    "    for bond in mol.GetBonds():\n",
    "        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "    g = nx.Graph(edges).to_directed()\n",
    "    edge_index = []\n",
    "    for e1, e2 in g.edges:\n",
    "        edge_index.append([e1, e2])\n",
    "        \n",
    "    return c_size, features, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222ab88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Task: Kd, Folds: 1 to 5\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'selectivity'\n",
    "task_name = 'Kd'\n",
    "START_FOLD = 1\n",
    "END_FOLD = 5\n",
    "ecfp_bits = 2048\n",
    "max_smiles_len = 44\n",
    "\n",
    "work_dir = '/home/rlawlsgurjh/hdd/work/MMFDL'\n",
    "vocab_path = os.path.join(work_dir, 'data', dataset_name, task_name, 'smiles_char_dict.pkl')\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'Using device: {device}')\n",
    "print(f'Task: {task_name}, Folds: {START_FOLD} to {END_FOLD}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eefd475",
   "metadata": {},
   "outputs": [],
   "source": [
    "argsCom = {\n",
    "    'num_features_smi': 44,\n",
    "    'num_features_ecfp': 2048,\n",
    "    'num_features_x': 78,\n",
    "    'dropout': 0.1, \n",
    "    'num_layer': 2,\n",
    "    'num_heads': 2,\n",
    "    'hidden_dim': 256,\n",
    "    'output_dim': 128,\n",
    "    'n_output': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a4bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary loaded: 42 characters\n"
     ]
    }
   ],
   "source": [
    "with open(vocab_path, 'rb') as f:\n",
    "    smilesVoc = pickle.load(f)\n",
    "print(f'Vocabulary loaded: {len(smilesVoc)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd088f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smiles_to_tensor(smiles_list, smilesVoc, max_smiles_len, ecfp_bits):\n",
    "    encoded_smi_list = []\n",
    "    ecfp_list = []\n",
    "    graph_data_list = []\n",
    "    valid_smiles = []\n",
    "    \n",
    "    for smi in smiles_list:\n",
    "        try:\n",
    "            # SMILES encoding\n",
    "            encoded_smi = make_variable_one(smi, smilesVoc, max_smiles_len)\n",
    "            \n",
    "            # Generate ECFP\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            if mol is None:\n",
    "                continue\n",
    "            if mol.HasSubstructMatch(Chem.MolFromSmarts(\"[H]\")):\n",
    "                mol = Chem.RemoveHs(mol)\n",
    "            ecfp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=ecfp_bits)\n",
    "            ecfp_array = np.array(ecfp, dtype=np.float32)\n",
    "            \n",
    "            # Generate Graph\n",
    "            c_size, features, edge_index = smile_to_graph(smi)\n",
    "            if edge_index == [] or features is None:\n",
    "                continue\n",
    "            \n",
    "            encoded_smi_list.append(encoded_smi)\n",
    "            ecfp_list.append(ecfp_array)\n",
    "            graph_data_list.append((c_size, features, edge_index))\n",
    "            valid_smiles.append(smi)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f'Error processing SMILES {smi}: {e}')\n",
    "            continue\n",
    "    \n",
    "    return encoded_smi_list, ecfp_list, graph_data_list, valid_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab83b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model, encoded_smi_list, ecfp_list, graph_data_list, weights, device):\n",
    "    all_unified_embeddings = []\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for encoded_smi, ecfp, (c_size, features, edge_index) in zip(\n",
    "            encoded_smi_list, ecfp_list, graph_data_list\n",
    "        ):\n",
    "            encodedSmi = torch.LongTensor([encoded_smi]).to(device)\n",
    "            encoded_smi_array = np.array([encoded_smi])\n",
    "            encodedSmi_mask = torch.LongTensor(getInput_mask(encoded_smi_array)).to(device)\n",
    "            ecfp_tensor = torch.FloatTensor([ecfp]).to(device)\n",
    "            \n",
    "            x = torch.Tensor(np.array(features)).to(device)\n",
    "            edge_index_array = np.array(edge_index)\n",
    "            if edge_index_array.shape[0] != 2:\n",
    "                edge_index_array = edge_index_array.transpose(1, 0)\n",
    "            edge_index_tensor = torch.LongTensor(edge_index_array).to(device)\n",
    "            batch = torch.zeros(x.shape[0], dtype=torch.long).to(device)\n",
    "            \n",
    "            smi_emb, ep_emb, gc_emb = model.get_embeddings(\n",
    "                encodedSmi, encodedSmi_mask, ecfp_tensor, x, edge_index_tensor, batch\n",
    "            )\n",
    "            \n",
    "            smi_emb_np = smi_emb.cpu().numpy().flatten() # (256,)\n",
    "            ep_emb_np = ep_emb.cpu().numpy().flatten()   # (128,)\n",
    "            gc_emb_np = gc_emb.cpu().numpy().flatten()   # (?)\n",
    "\n",
    "            fused_vector = np.concatenate([\n",
    "                weights[0] * smi_emb_np, \n",
    "                weights[1] * ep_emb_np, \n",
    "                weights[2] * gc_emb_np\n",
    "            ])\n",
    "            \n",
    "            all_unified_embeddings.append(fused_vector)\n",
    "    \n",
    "    return np.array(all_unified_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbce08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[Fold 1] Processing...\n",
      "================================================================================\n",
      "[INFO] Loading data from /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Kd/fold1\n",
      "Train: 399, Val: 45, Train+Val: 444, Test: 112\n",
      "[INFO] Loading model from /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold1/best_model.pt\n",
      "Model loaded from epoch 50, val_loss: 0.2395\n",
      "Loaded weights: [0.69886494 0.23145324 0.07628601]\n",
      "[INFO] Processing Train+Val data...\n",
      "  Successfully processed 444 SMILES\n",
      "[INFO] Processing Test data...\n",
      "  Successfully processed 112 SMILES\n",
      "[INFO] Extracting Train+Val embeddings...\n",
      "  Train+Val embeddings shape: (444, 540)\n",
      "[INFO] Extracting Test embeddings...\n",
      "  Test embeddings shape: (112, 540)\n",
      "[INFO] Saved Train+Val embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold1/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved Test embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold1/embeddings/te_embeddings.npy\n",
      "[Fold 1] Completed!\n",
      "\n",
      "================================================================================\n",
      "[Fold 2] Processing...\n",
      "================================================================================\n",
      "[INFO] Loading data from /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Kd/fold2\n",
      "Train: 400, Val: 45, Train+Val: 445, Test: 111\n",
      "[INFO] Loading model from /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold2/best_model.pt\n",
      "Model loaded from epoch 48, val_loss: 0.3206\n",
      "Loaded weights: [0.67680204 0.28271806 0.05288437]\n",
      "[INFO] Processing Train+Val data...\n",
      "  Successfully processed 445 SMILES\n",
      "[INFO] Processing Test data...\n",
      "  Successfully processed 111 SMILES\n",
      "[INFO] Extracting Train+Val embeddings...\n",
      "  Train+Val embeddings shape: (445, 540)\n",
      "[INFO] Extracting Test embeddings...\n",
      "  Test embeddings shape: (111, 540)\n",
      "[INFO] Saved Train+Val embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold2/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved Test embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold2/embeddings/te_embeddings.npy\n",
      "[Fold 2] Completed!\n",
      "\n",
      "================================================================================\n",
      "[Fold 3] Processing...\n",
      "================================================================================\n",
      "[INFO] Loading data from /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Kd/fold3\n",
      "Train: 400, Val: 45, Train+Val: 445, Test: 111\n",
      "[INFO] Loading model from /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold3/best_model.pt\n",
      "Model loaded from epoch 50, val_loss: 0.3566\n",
      "Loaded weights: [0.6988709  0.25497428 0.05621002]\n",
      "[INFO] Processing Train+Val data...\n",
      "  Successfully processed 445 SMILES\n",
      "[INFO] Processing Test data...\n",
      "  Successfully processed 111 SMILES\n",
      "[INFO] Extracting Train+Val embeddings...\n",
      "  Train+Val embeddings shape: (445, 540)\n",
      "[INFO] Extracting Test embeddings...\n",
      "  Test embeddings shape: (111, 540)\n",
      "[INFO] Saved Train+Val embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold3/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved Test embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold3/embeddings/te_embeddings.npy\n",
      "[Fold 3] Completed!\n",
      "\n",
      "================================================================================\n",
      "[Fold 4] Processing...\n",
      "================================================================================\n",
      "[INFO] Loading data from /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Kd/fold4\n",
      "Train: 400, Val: 45, Train+Val: 445, Test: 111\n",
      "[INFO] Loading model from /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold4/best_model.pt\n",
      "Model loaded from epoch 50, val_loss: 0.1069\n",
      "Loaded weights: [0.6852251  0.22592722 0.09089263]\n",
      "[INFO] Processing Train+Val data...\n",
      "  Successfully processed 445 SMILES\n",
      "[INFO] Processing Test data...\n",
      "  Successfully processed 111 SMILES\n",
      "[INFO] Extracting Train+Val embeddings...\n",
      "  Train+Val embeddings shape: (445, 540)\n",
      "[INFO] Extracting Test embeddings...\n",
      "  Test embeddings shape: (111, 540)\n",
      "[INFO] Saved Train+Val embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold4/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved Test embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold4/embeddings/te_embeddings.npy\n",
      "[Fold 4] Completed!\n",
      "\n",
      "================================================================================\n",
      "[Fold 5] Processing...\n",
      "================================================================================\n",
      "[INFO] Loading data from /home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/Kd/fold5\n",
      "Train: 400, Val: 45, Train+Val: 445, Test: 111\n",
      "[INFO] Loading model from /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold5/best_model.pt\n",
      "Model loaded from epoch 49, val_loss: 0.1537\n",
      "Loaded weights: [0.69347167 0.22465956 0.08552577]\n",
      "[INFO] Processing Train+Val data...\n",
      "  Successfully processed 445 SMILES\n",
      "[INFO] Processing Test data...\n",
      "  Successfully processed 111 SMILES\n",
      "[INFO] Extracting Train+Val embeddings...\n",
      "  Train+Val embeddings shape: (445, 540)\n",
      "[INFO] Extracting Test embeddings...\n",
      "  Test embeddings shape: (111, 540)\n",
      "[INFO] Saved Train+Val embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold5/embeddings/tr_val_embeddings.npy\n",
      "[INFO] Saved Test embeddings to /home/rlawlsgurjh/hdd/work/MMFDL/results/SGD/selectivity/Kd/fold5/embeddings/te_embeddings.npy\n",
      "[Fold 5] Completed!\n",
      "\n",
      "================================================================================\n",
      "[INFO] All folds processed!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for fold_num in range(START_FOLD, END_FOLD + 1):\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"[Fold {fold_num}] Processing...\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    data_dir = f'/home/rlawlsgurjh/hdd/work/ChEMBLv2/data/selectivity_processed/{task_name}/fold{fold_num}'\n",
    "\n",
    "    print(f\"[INFO] Loading data from {data_dir}\")\n",
    "    df_train = pd.read_csv(os.path.join(data_dir, 'selectivity_train.csv'))\n",
    "    df_val = pd.read_csv(os.path.join(data_dir, 'selectivity_val.csv'))\n",
    "    df_test = pd.read_csv(os.path.join(data_dir, 'selectivity_test.csv'))\n",
    "\n",
    "    df_train_val = pd.concat([df_train, df_val], ignore_index=True)\n",
    "    \n",
    "    print(f\"Train: {len(df_train)}, Val: {len(df_val)}, Train+Val: {len(df_train_val)}, Test: {len(df_test)}\")\n",
    "\n",
    "    X_train_val = df_train_val['SMILES'].values\n",
    "    y_train_val = df_train_val['Ssel'].values.astype(np.float32)\n",
    "    \n",
    "    X_test = df_test['SMILES'].values\n",
    "    y_test = df_test['Ssel'].values.astype(np.float32)\n",
    "    \n",
    "    checkpoint_dir = os.path.join(work_dir, 'results', 'SGD', dataset_name, task_name, f'fold{fold_num}')\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, 'best_model.pt')\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(f'Warning: Checkpoint file not found: {checkpoint_path}')\n",
    "        continue\n",
    "    \n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    best_epoch = checkpoint['epoch']\n",
    "    \n",
    "    weight_path = os.path.join(checkpoint_dir, \n",
    "                               f'{dataset_name}_{task_name}_fold{fold_num}_weight_epoch_{best_epoch}.csv')\n",
    "    \n",
    "    if not os.path.exists(weight_path):\n",
    "        print(f'Warning: Weight file not found: {weight_path}')\n",
    "        continue\n",
    "\n",
    "    print(f\"[INFO] Loading model from {checkpoint_path}\")\n",
    "    model = comModel(argsCom).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(f'Model loaded from epoch {checkpoint[\"epoch\"]}, val_loss: {checkpoint[\"val_loss\"]:.4f}')\n",
    "\n",
    "    weight_df = pd.read_csv(weight_path)\n",
    "    weight_dict = dict(zip(weight_df['Key'], weight_df['Value']))\n",
    "    weights = np.array([weight_dict[1], weight_dict[2], weight_dict[3]])\n",
    "    print(f'Loaded weights: {weights}')\n",
    "    \n",
    "\n",
    "    print(\"[INFO] Processing Train+Val data...\")\n",
    "    encoded_smi_train_val, ecfp_train_val, graph_train_val, valid_smiles_train_val = process_smiles_to_tensor(\n",
    "        X_train_val.tolist(), smilesVoc, max_smiles_len, ecfp_bits\n",
    "    )\n",
    "    print(f\"  Successfully processed {len(encoded_smi_train_val)} SMILES\")\n",
    "    \n",
    "\n",
    "    print(\"[INFO] Processing Test data...\")\n",
    "    encoded_smi_test, ecfp_test, graph_test, valid_smiles_test = process_smiles_to_tensor(\n",
    "        X_test.tolist(), smilesVoc, max_smiles_len, ecfp_bits\n",
    "    )\n",
    "    print(f\"  Successfully processed {len(encoded_smi_test)} SMILES\")\n",
    "    \n",
    "\n",
    "    print(\"[INFO] Extracting Train+Val embeddings...\")\n",
    "    emb_train_val = extract_embeddings(model, encoded_smi_train_val, ecfp_train_val, graph_train_val, weights, device)\n",
    "    print(f\"  Train+Val embeddings shape: {emb_train_val.shape}\")\n",
    "    \n",
    "\n",
    "    print(\"[INFO] Extracting Test embeddings...\")\n",
    "    emb_test = extract_embeddings(model, encoded_smi_test, ecfp_test, graph_test, weights, device)\n",
    "    print(f\"  Test embeddings shape: {emb_test.shape}\")\n",
    "    \n",
    "\n",
    "    output_dir = os.path.join(work_dir, 'results', 'SGD', dataset_name, task_name,\n",
    "                              f'fold{fold_num}', 'embeddings')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "\n",
    "    tr_val_path = os.path.join(output_dir, f'tr_val_embeddings.npy')\n",
    "    te_path = os.path.join(output_dir, f'te_embeddings.npy')\n",
    "    \n",
    "    np.save(tr_val_path, {\n",
    "        'embeddings': emb_train_val,\n",
    "        'Ssel': y_train_val[:len(emb_train_val)],\n",
    "        'SMILES': valid_smiles_train_val,\n",
    "    })\n",
    "    print(f\"[INFO] Saved Train+Val embeddings to {tr_val_path}\")\n",
    "    \n",
    "    np.save(te_path, {\n",
    "        'embeddings': emb_test,\n",
    "        'Ssel': y_test[:len(emb_test)],\n",
    "        'SMILES': valid_smiles_test,\n",
    "    })\n",
    "    print(f\"[INFO] Saved Test embeddings to {te_path}\")\n",
    "    \n",
    "    print(f\"[Fold {fold_num}] Completed!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] All folds processed!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674ebfad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b07a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ac476",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff7b2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
