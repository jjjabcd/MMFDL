{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from mmfdl.util.utils_smiecfp import *\n",
    "from mmfdl.util.data_gen_modify import *\n",
    "from mmfdl.util.analysis import *\n",
    "from mmfdl.util.utils import formDataset_Single\n",
    "from mmfdl.util.normalization import LabelNormalizer\n",
    "\n",
    "from mmfdl.model.model_combination import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score\n",
    "from scipy.stats import pearsonr\n",
    "from torch_geometric.loader import DataLoader\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch_geometric\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Attempting to run cuBLAS.*\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*weights_only.*\")\n",
    "\n",
    "gpu_index = 0\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    _ = torch.zeros(1).cuda()\n",
    "device = torch.device(f'cuda:{gpu_index}' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Starting training for selectivity Kd S(1uM)_label\n",
      "Folds: 1 to 5\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'Caco2_Wang'\n",
    "target_col = 'Caco2_Wang'\n",
    "\n",
    "########################\n",
    "version = 'v1'\n",
    "#########################\n",
    "\n",
    "start_fold = 1\n",
    "end_fold = 5\n",
    "epochs = 50\n",
    "batch_size = 256\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "argsCom = {\n",
    "    'num_features_smi': 44,\n",
    "    'num_features_ecfp': 2048,\n",
    "    'num_features_x': 78,\n",
    "    'dropout': 0.1, \n",
    "    'num_layer': 2,\n",
    "    'num_heads': 2,\n",
    "    'hidden_dim': 256,\n",
    "    'output_dim': 128,\n",
    "    'n_output': 1\n",
    "}\n",
    "\n",
    "print('=' * 60)\n",
    "print(f'Starting training for {dataset_name} {target_col}')\n",
    "print(f'Folds: {start_fold} to {end_fold}')\n",
    "print('=' * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing Fold 1\n",
      "============================================================\n",
      "Loading datasets for selectivity Kd fold 1\n",
      "Train samples: 399\n",
      "Validation samples: 45\n",
      "Test samples: 112\n",
      "============================================================\n",
      "Running EPOCH 1\n",
      "train avg_loss is:  0.20643393695354462\n",
      "val avg_loss is:  0.19250378012657166\n",
      "  -> Best model saved! (epoch 1, val_loss: 0.1925)\n",
      "\n",
      "\n",
      "Running EPOCH 2\n",
      "train avg_loss is:  0.1913772076368332\n",
      "val avg_loss is:  0.17698466777801514\n",
      "  -> Best model saved! (epoch 2, val_loss: 0.1770)\n",
      "\n",
      "\n",
      "Running EPOCH 3\n",
      "train avg_loss is:  0.18181867897510529\n",
      "val avg_loss is:  0.17092552781105042\n",
      "  -> Best model saved! (epoch 3, val_loss: 0.1709)\n",
      "\n",
      "\n",
      "Running EPOCH 4\n",
      "train avg_loss is:  0.17559103667736053\n",
      "val avg_loss is:  0.16369488835334778\n",
      "  -> Best model saved! (epoch 4, val_loss: 0.1637)\n",
      "\n",
      "\n",
      "Running EPOCH 5\n",
      "train avg_loss is:  0.16938114166259766\n",
      "val avg_loss is:  0.15843887627124786\n",
      "  -> Best model saved! (epoch 5, val_loss: 0.1584)\n",
      "\n",
      "\n",
      "Running EPOCH 6\n",
      "train avg_loss is:  0.16665738821029663\n",
      "val avg_loss is:  0.1549561321735382\n",
      "  -> Best model saved! (epoch 6, val_loss: 0.1550)\n",
      "\n",
      "\n",
      "Running EPOCH 7\n",
      "train avg_loss is:  0.16807827353477478\n",
      "val avg_loss is:  0.15283113718032837\n",
      "  -> Best model saved! (epoch 7, val_loss: 0.1528)\n",
      "\n",
      "\n",
      "Running EPOCH 8\n",
      "train avg_loss is:  0.16112825274467468\n",
      "val avg_loss is:  0.15015366673469543\n",
      "  -> Best model saved! (epoch 8, val_loss: 0.1502)\n",
      "\n",
      "\n",
      "Running EPOCH 9\n",
      "train avg_loss is:  0.15806257724761963\n",
      "val avg_loss is:  0.14728906750679016\n",
      "  -> Best model saved! (epoch 9, val_loss: 0.1473)\n",
      "\n",
      "\n",
      "Running EPOCH 10\n",
      "train avg_loss is:  0.15675780177116394\n",
      "val avg_loss is:  0.14558115601539612\n",
      "  -> Best model saved! (epoch 10, val_loss: 0.1456)\n",
      "\n",
      "\n",
      "Running EPOCH 11\n",
      "train avg_loss is:  0.15574443340301514\n",
      "val avg_loss is:  0.14477954804897308\n",
      "  -> Best model saved! (epoch 11, val_loss: 0.1448)\n",
      "\n",
      "\n",
      "Running EPOCH 12\n",
      "train avg_loss is:  0.15283147990703583\n",
      "val avg_loss is:  0.14223423600196838\n",
      "  -> Best model saved! (epoch 12, val_loss: 0.1422)\n",
      "\n",
      "\n",
      "Running EPOCH 13\n",
      "train avg_loss is:  0.14846450090408325\n",
      "val avg_loss is:  0.1414925754070282\n",
      "  -> Best model saved! (epoch 13, val_loss: 0.1415)\n",
      "\n",
      "\n",
      "Running EPOCH 14\n",
      "train avg_loss is:  0.1511991024017334\n",
      "val avg_loss is:  0.1383012980222702\n",
      "  -> Best model saved! (epoch 14, val_loss: 0.1383)\n",
      "\n",
      "\n",
      "Running EPOCH 15\n",
      "train avg_loss is:  0.14937622845172882\n",
      "val avg_loss is:  0.13912050426006317\n",
      "\n",
      "\n",
      "Running EPOCH 16\n",
      "train avg_loss is:  0.1460215300321579\n",
      "val avg_loss is:  0.1369411051273346\n",
      "  -> Best model saved! (epoch 16, val_loss: 0.1369)\n",
      "\n",
      "\n",
      "Running EPOCH 17\n",
      "train avg_loss is:  0.14487895369529724\n",
      "val avg_loss is:  0.1332051157951355\n",
      "  -> Best model saved! (epoch 17, val_loss: 0.1332)\n",
      "\n",
      "\n",
      "Running EPOCH 18\n",
      "train avg_loss is:  0.14184483885765076\n",
      "val avg_loss is:  0.13148485124111176\n",
      "  -> Best model saved! (epoch 18, val_loss: 0.1315)\n",
      "\n",
      "\n",
      "Running EPOCH 19\n",
      "train avg_loss is:  0.14100360870361328\n",
      "val avg_loss is:  0.1312243938446045\n",
      "  -> Best model saved! (epoch 19, val_loss: 0.1312)\n",
      "\n",
      "\n",
      "Running EPOCH 20\n",
      "train avg_loss is:  0.13849098980426788\n",
      "val avg_loss is:  0.12853148579597473\n",
      "  -> Best model saved! (epoch 20, val_loss: 0.1285)\n",
      "\n",
      "\n",
      "Running EPOCH 21\n",
      "train avg_loss is:  0.1383521556854248\n",
      "val avg_loss is:  0.12734490633010864\n",
      "  -> Best model saved! (epoch 21, val_loss: 0.1273)\n",
      "\n",
      "\n",
      "Running EPOCH 22\n",
      "train avg_loss is:  0.13360494375228882\n",
      "val avg_loss is:  0.12469390034675598\n",
      "  -> Best model saved! (epoch 22, val_loss: 0.1247)\n",
      "\n",
      "\n",
      "Running EPOCH 23\n",
      "train avg_loss is:  0.13591188192367554\n",
      "val avg_loss is:  0.12586063146591187\n",
      "\n",
      "\n",
      "Running EPOCH 24\n",
      "train avg_loss is:  0.12858188152313232\n",
      "val avg_loss is:  0.12171512842178345\n",
      "  -> Best model saved! (epoch 24, val_loss: 0.1217)\n",
      "\n",
      "\n",
      "Running EPOCH 25\n",
      "train avg_loss is:  0.13082851469516754\n",
      "val avg_loss is:  0.12429903447628021\n",
      "\n",
      "\n",
      "Running EPOCH 26\n",
      "train avg_loss is:  0.13139984011650085\n",
      "val avg_loss is:  0.1229105293750763\n",
      "\n",
      "\n",
      "Running EPOCH 27\n",
      "train avg_loss is:  0.1270904541015625\n",
      "val avg_loss is:  0.12267135083675385\n",
      "\n",
      "\n",
      "Running EPOCH 28\n",
      "train avg_loss is:  0.12358257919549942\n",
      "val avg_loss is:  0.12111039459705353\n",
      "  -> Best model saved! (epoch 28, val_loss: 0.1211)\n",
      "\n",
      "\n",
      "Running EPOCH 29\n",
      "train avg_loss is:  0.1255214512348175\n",
      "val avg_loss is:  0.12028004974126816\n",
      "  -> Best model saved! (epoch 29, val_loss: 0.1203)\n",
      "\n",
      "\n",
      "Running EPOCH 30\n",
      "train avg_loss is:  0.12282359600067139\n",
      "val avg_loss is:  0.11829681694507599\n",
      "  -> Best model saved! (epoch 30, val_loss: 0.1183)\n",
      "\n",
      "\n",
      "Running EPOCH 31\n",
      "train avg_loss is:  0.12046337127685547\n",
      "val avg_loss is:  0.11742496490478516\n",
      "  -> Best model saved! (epoch 31, val_loss: 0.1174)\n",
      "\n",
      "\n",
      "Running EPOCH 32\n",
      "train avg_loss is:  0.12039089947938919\n",
      "val avg_loss is:  0.11700461804866791\n",
      "  -> Best model saved! (epoch 32, val_loss: 0.1170)\n",
      "\n",
      "\n",
      "Running EPOCH 33\n",
      "train avg_loss is:  0.12511762976646423\n",
      "val avg_loss is:  0.11696086823940277\n",
      "  -> Best model saved! (epoch 33, val_loss: 0.1170)\n",
      "\n",
      "\n",
      "Running EPOCH 34\n",
      "train avg_loss is:  0.11860347539186478\n",
      "val avg_loss is:  0.11738064885139465\n",
      "\n",
      "\n",
      "Running EPOCH 35\n",
      "train avg_loss is:  0.11930893361568451\n",
      "val avg_loss is:  0.11673649400472641\n",
      "  -> Best model saved! (epoch 35, val_loss: 0.1167)\n",
      "\n",
      "\n",
      "Running EPOCH 36\n",
      "train avg_loss is:  0.11717003583908081\n",
      "val avg_loss is:  0.11559935659170151\n",
      "  -> Best model saved! (epoch 36, val_loss: 0.1156)\n",
      "\n",
      "\n",
      "Running EPOCH 37\n",
      "train avg_loss is:  0.11773954331874847\n",
      "val avg_loss is:  0.11426802724599838\n",
      "  -> Best model saved! (epoch 37, val_loss: 0.1143)\n",
      "\n",
      "\n",
      "Running EPOCH 38\n",
      "train avg_loss is:  0.11716420948505402\n",
      "val avg_loss is:  0.1148802787065506\n",
      "\n",
      "\n",
      "Running EPOCH 39\n",
      "train avg_loss is:  0.11441932618618011\n",
      "val avg_loss is:  0.11450903117656708\n",
      "\n",
      "\n",
      "Running EPOCH 40\n",
      "train avg_loss is:  0.11852164566516876\n",
      "val avg_loss is:  0.11292179673910141\n",
      "  -> Best model saved! (epoch 40, val_loss: 0.1129)\n",
      "\n",
      "\n",
      "Running EPOCH 41\n",
      "train avg_loss is:  0.11533280462026596\n",
      "val avg_loss is:  0.11491572111845016\n",
      "\n",
      "\n",
      "Running EPOCH 42\n",
      "train avg_loss is:  0.11229291558265686\n",
      "val avg_loss is:  0.11244773864746094\n",
      "  -> Best model saved! (epoch 42, val_loss: 0.1124)\n",
      "\n",
      "\n",
      "Running EPOCH 43\n",
      "train avg_loss is:  0.11387605965137482\n",
      "val avg_loss is:  0.11190690845251083\n",
      "  -> Best model saved! (epoch 43, val_loss: 0.1119)\n",
      "\n",
      "\n",
      "Running EPOCH 44\n",
      "train avg_loss is:  0.1133958026766777\n",
      "val avg_loss is:  0.11102344840765\n",
      "  -> Best model saved! (epoch 44, val_loss: 0.1110)\n",
      "\n",
      "\n",
      "Running EPOCH 45\n",
      "train avg_loss is:  0.1109735295176506\n",
      "val avg_loss is:  0.11096464097499847\n",
      "  -> Best model saved! (epoch 45, val_loss: 0.1110)\n",
      "\n",
      "\n",
      "Running EPOCH 46\n",
      "train avg_loss is:  0.10861463099718094\n",
      "val avg_loss is:  0.1135464459657669\n",
      "\n",
      "\n",
      "Running EPOCH 47\n",
      "train avg_loss is:  0.11001861840486526\n",
      "val avg_loss is:  0.10821082442998886\n",
      "  -> Best model saved! (epoch 47, val_loss: 0.1082)\n",
      "\n",
      "\n",
      "Running EPOCH 48\n",
      "train avg_loss is:  0.10993845760822296\n",
      "val avg_loss is:  0.10931485891342163\n",
      "\n",
      "\n",
      "Running EPOCH 49\n",
      "train avg_loss is:  0.10935815423727036\n",
      "val avg_loss is:  0.10899090021848679\n",
      "\n",
      "\n",
      "Running EPOCH 50\n",
      "train avg_loss is:  0.10907542705535889\n",
      "val avg_loss is:  0.10931423306465149\n",
      "\n",
      "\n",
      "Loading best model from checkpoint: results/SGD/selectivity/Kd/S(1uM)_label/v1/fold1/best_model.pt\n",
      "Best model loaded: epoch 47, val_loss: 0.1082\n",
      "Running EPOCH 1\n",
      "weight loss is:  0.2526923716068268\n",
      "Running EPOCH 2\n",
      "weight loss is:  0.25268006324768066\n",
      "Running EPOCH 3\n",
      "weight loss is:  0.2526678442955017\n",
      "Running EPOCH 4\n",
      "weight loss is:  0.25265568494796753\n",
      "Running EPOCH 5\n",
      "weight loss is:  0.25264355540275574\n",
      "Running EPOCH 6\n",
      "weight loss is:  0.2526315152645111\n",
      "Running EPOCH 7\n",
      "weight loss is:  0.25261950492858887\n",
      "Running EPOCH 8\n",
      "weight loss is:  0.2526076138019562\n",
      "Running EPOCH 9\n",
      "weight loss is:  0.2525957524776459\n",
      "Running EPOCH 10\n",
      "weight loss is:  0.25258395075798035\n",
      "Running EPOCH 11\n",
      "weight loss is:  0.252572238445282\n",
      "Running EPOCH 12\n",
      "weight loss is:  0.2525605261325836\n",
      "Running EPOCH 13\n",
      "weight loss is:  0.2525489330291748\n",
      "Running EPOCH 14\n",
      "weight loss is:  0.25253742933273315\n",
      "Running EPOCH 15\n",
      "weight loss is:  0.2525258958339691\n",
      "Running EPOCH 16\n",
      "weight loss is:  0.25251448154449463\n",
      "Running EPOCH 17\n",
      "weight loss is:  0.2525031268596649\n",
      "Running EPOCH 18\n",
      "weight loss is:  0.25249183177948\n",
      "Running EPOCH 19\n",
      "weight loss is:  0.25248056650161743\n",
      "Running EPOCH 20\n",
      "weight loss is:  0.25246942043304443\n",
      "Running EPOCH 21\n",
      "weight loss is:  0.2524583041667938\n",
      "Running EPOCH 22\n",
      "weight loss is:  0.252447247505188\n",
      "Running EPOCH 23\n",
      "weight loss is:  0.25243625044822693\n",
      "Running EPOCH 24\n",
      "weight loss is:  0.25242531299591064\n",
      "Running EPOCH 25\n",
      "weight loss is:  0.2524144649505615\n",
      "Running EPOCH 26\n",
      "weight loss is:  0.2524036467075348\n",
      "Running EPOCH 27\n",
      "weight loss is:  0.25239288806915283\n",
      "Running EPOCH 28\n",
      "weight loss is:  0.25238218903541565\n",
      "Running EPOCH 29\n",
      "weight loss is:  0.252371609210968\n",
      "Running EPOCH 30\n",
      "weight loss is:  0.252360999584198\n",
      "Running EPOCH 31\n",
      "weight loss is:  0.2523505389690399\n",
      "Running EPOCH 32\n",
      "weight loss is:  0.25234007835388184\n",
      "Running EPOCH 33\n",
      "weight loss is:  0.25232967734336853\n",
      "Running EPOCH 34\n",
      "weight loss is:  0.2523193955421448\n",
      "Running EPOCH 35\n",
      "weight loss is:  0.252309113740921\n",
      "Running EPOCH 36\n",
      "weight loss is:  0.25229892134666443\n",
      "Running EPOCH 37\n",
      "weight loss is:  0.2522887885570526\n",
      "Running EPOCH 38\n",
      "weight loss is:  0.2522786855697632\n",
      "Running EPOCH 39\n",
      "weight loss is:  0.25226864218711853\n",
      "Running EPOCH 40\n",
      "weight loss is:  0.25225868821144104\n",
      "Running EPOCH 41\n",
      "weight loss is:  0.2522488236427307\n",
      "Running EPOCH 42\n",
      "weight loss is:  0.2522389590740204\n",
      "Running EPOCH 43\n",
      "weight loss is:  0.25222915410995483\n",
      "Running EPOCH 44\n",
      "weight loss is:  0.25221943855285645\n",
      "Running EPOCH 45\n",
      "weight loss is:  0.25220978260040283\n",
      "Running EPOCH 46\n",
      "weight loss is:  0.2522001564502716\n",
      "Running EPOCH 47\n",
      "weight loss is:  0.25219061970710754\n",
      "Running EPOCH 48\n",
      "weight loss is:  0.25218114256858826\n",
      "Running EPOCH 49\n",
      "weight loss is:  0.25217172503471375\n",
      "Running EPOCH 50\n",
      "weight loss is:  0.2521623373031616\n",
      "\n",
      "\n",
      "{1: np.float32(0.6767906), 2: np.float32(0.2058824), 3: np.float32(0.118377954)}\n",
      "Fold 1 Metrics:\n",
      "  ACC: 0.8750\n",
      "  F1: 0.9307\n",
      "  AUC: 0.8087\n",
      "  Precision: 0.8785\n",
      "  Recall: 0.9895\n",
      "\n",
      "\n",
      "Fold 1 completed!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Processing Fold 2\n",
      "============================================================\n",
      "Loading datasets for selectivity Kd fold 2\n",
      "Train samples: 400\n",
      "Validation samples: 45\n",
      "Test samples: 111\n",
      "============================================================\n",
      "Running EPOCH 1\n",
      "train avg_loss is:  0.22582939267158508\n",
      "val avg_loss is:  0.20179365575313568\n",
      "  -> Best model saved! (epoch 1, val_loss: 0.2018)\n",
      "\n",
      "\n",
      "Running EPOCH 2\n",
      "train avg_loss is:  0.20590543746948242\n",
      "val avg_loss is:  0.18762478232383728\n",
      "  -> Best model saved! (epoch 2, val_loss: 0.1876)\n",
      "\n",
      "\n",
      "Running EPOCH 3\n",
      "train avg_loss is:  0.19345958530902863\n",
      "val avg_loss is:  0.17516598105430603\n",
      "  -> Best model saved! (epoch 3, val_loss: 0.1752)\n",
      "\n",
      "\n",
      "Running EPOCH 4\n",
      "train avg_loss is:  0.18670473992824554\n",
      "val avg_loss is:  0.16691938042640686\n",
      "  -> Best model saved! (epoch 4, val_loss: 0.1669)\n",
      "\n",
      "\n",
      "Running EPOCH 5\n",
      "train avg_loss is:  0.18206283450126648\n",
      "val avg_loss is:  0.16127346456050873\n",
      "  -> Best model saved! (epoch 5, val_loss: 0.1613)\n",
      "\n",
      "\n",
      "Running EPOCH 6\n",
      "train avg_loss is:  0.17685547471046448\n",
      "val avg_loss is:  0.15713632106781006\n",
      "  -> Best model saved! (epoch 6, val_loss: 0.1571)\n",
      "\n",
      "\n",
      "Running EPOCH 7\n",
      "train avg_loss is:  0.17852681875228882\n",
      "val avg_loss is:  0.15527844429016113\n",
      "  -> Best model saved! (epoch 7, val_loss: 0.1553)\n",
      "\n",
      "\n",
      "Running EPOCH 8\n",
      "train avg_loss is:  0.17315421998500824\n",
      "val avg_loss is:  0.15054693818092346\n",
      "  -> Best model saved! (epoch 8, val_loss: 0.1505)\n",
      "\n",
      "\n",
      "Running EPOCH 9\n",
      "train avg_loss is:  0.17005103826522827\n",
      "val avg_loss is:  0.14750543236732483\n",
      "  -> Best model saved! (epoch 9, val_loss: 0.1475)\n",
      "\n",
      "\n",
      "Running EPOCH 10\n",
      "train avg_loss is:  0.16610762476921082\n",
      "val avg_loss is:  0.14407312870025635\n",
      "  -> Best model saved! (epoch 10, val_loss: 0.1441)\n",
      "\n",
      "\n",
      "Running EPOCH 11\n",
      "train avg_loss is:  0.16336707770824432\n",
      "val avg_loss is:  0.1427551805973053\n",
      "  -> Best model saved! (epoch 11, val_loss: 0.1428)\n",
      "\n",
      "\n",
      "Running EPOCH 12\n",
      "train avg_loss is:  0.16270458698272705\n",
      "val avg_loss is:  0.1400453746318817\n",
      "  -> Best model saved! (epoch 12, val_loss: 0.1400)\n",
      "\n",
      "\n",
      "Running EPOCH 13\n",
      "train avg_loss is:  0.1625257432460785\n",
      "val avg_loss is:  0.13659259676933289\n",
      "  -> Best model saved! (epoch 13, val_loss: 0.1366)\n",
      "\n",
      "\n",
      "Running EPOCH 14\n",
      "train avg_loss is:  0.15836049616336823\n",
      "val avg_loss is:  0.1349937617778778\n",
      "  -> Best model saved! (epoch 14, val_loss: 0.1350)\n",
      "\n",
      "\n",
      "Running EPOCH 15\n",
      "train avg_loss is:  0.15321531891822815\n",
      "val avg_loss is:  0.13285081088542938\n",
      "  -> Best model saved! (epoch 15, val_loss: 0.1329)\n",
      "\n",
      "\n",
      "Running EPOCH 16\n",
      "train avg_loss is:  0.15287119150161743\n",
      "val avg_loss is:  0.1302575320005417\n",
      "  -> Best model saved! (epoch 16, val_loss: 0.1303)\n",
      "\n",
      "\n",
      "Running EPOCH 17\n",
      "train avg_loss is:  0.15026599168777466\n",
      "val avg_loss is:  0.12678992748260498\n",
      "  -> Best model saved! (epoch 17, val_loss: 0.1268)\n",
      "\n",
      "\n",
      "Running EPOCH 18\n",
      "train avg_loss is:  0.14725682139396667\n",
      "val avg_loss is:  0.12345798313617706\n",
      "  -> Best model saved! (epoch 18, val_loss: 0.1235)\n",
      "\n",
      "\n",
      "Running EPOCH 19\n",
      "train avg_loss is:  0.1432959884405136\n",
      "val avg_loss is:  0.12079624831676483\n",
      "  -> Best model saved! (epoch 19, val_loss: 0.1208)\n",
      "\n",
      "\n",
      "Running EPOCH 20\n",
      "train avg_loss is:  0.14225119352340698\n",
      "val avg_loss is:  0.1189333125948906\n",
      "  -> Best model saved! (epoch 20, val_loss: 0.1189)\n",
      "\n",
      "\n",
      "Running EPOCH 21\n",
      "train avg_loss is:  0.14236515760421753\n",
      "val avg_loss is:  0.115821473300457\n",
      "  -> Best model saved! (epoch 21, val_loss: 0.1158)\n",
      "\n",
      "\n",
      "Running EPOCH 22\n",
      "train avg_loss is:  0.1360348016023636\n",
      "val avg_loss is:  0.11394312977790833\n",
      "  -> Best model saved! (epoch 22, val_loss: 0.1139)\n",
      "\n",
      "\n",
      "Running EPOCH 23\n",
      "train avg_loss is:  0.13817039132118225\n",
      "val avg_loss is:  0.11262015998363495\n",
      "  -> Best model saved! (epoch 23, val_loss: 0.1126)\n",
      "\n",
      "\n",
      "Running EPOCH 24\n",
      "train avg_loss is:  0.13430167734622955\n",
      "val avg_loss is:  0.1108764037489891\n",
      "  -> Best model saved! (epoch 24, val_loss: 0.1109)\n",
      "\n",
      "\n",
      "Running EPOCH 25\n",
      "train avg_loss is:  0.1348501592874527\n",
      "val avg_loss is:  0.10931016504764557\n",
      "  -> Best model saved! (epoch 25, val_loss: 0.1093)\n",
      "\n",
      "\n",
      "Running EPOCH 26\n",
      "train avg_loss is:  0.13384556770324707\n",
      "val avg_loss is:  0.10764427483081818\n",
      "  -> Best model saved! (epoch 26, val_loss: 0.1076)\n",
      "\n",
      "\n",
      "Running EPOCH 27\n",
      "train avg_loss is:  0.13271138072013855\n",
      "val avg_loss is:  0.1098092794418335\n",
      "\n",
      "\n",
      "Running EPOCH 28\n",
      "train avg_loss is:  0.12709589302539825\n",
      "val avg_loss is:  0.10644011199474335\n",
      "  -> Best model saved! (epoch 28, val_loss: 0.1064)\n",
      "\n",
      "\n",
      "Running EPOCH 29\n",
      "train avg_loss is:  0.13027894496917725\n",
      "val avg_loss is:  0.10438215732574463\n",
      "  -> Best model saved! (epoch 29, val_loss: 0.1044)\n",
      "\n",
      "\n",
      "Running EPOCH 30\n",
      "train avg_loss is:  0.12997937202453613\n",
      "val avg_loss is:  0.10272403806447983\n",
      "  -> Best model saved! (epoch 30, val_loss: 0.1027)\n",
      "\n",
      "\n",
      "Running EPOCH 31\n",
      "train avg_loss is:  0.1247185543179512\n",
      "val avg_loss is:  0.10226686298847198\n",
      "  -> Best model saved! (epoch 31, val_loss: 0.1023)\n",
      "\n",
      "\n",
      "Running EPOCH 32\n",
      "train avg_loss is:  0.12725061178207397\n",
      "val avg_loss is:  0.10020508617162704\n",
      "  -> Best model saved! (epoch 32, val_loss: 0.1002)\n",
      "\n",
      "\n",
      "Running EPOCH 33\n",
      "train avg_loss is:  0.12103388458490372\n",
      "val avg_loss is:  0.10067503154277802\n",
      "\n",
      "\n",
      "Running EPOCH 34\n",
      "train avg_loss is:  0.12296677380800247\n",
      "val avg_loss is:  0.10062297433614731\n",
      "\n",
      "\n",
      "Running EPOCH 35\n",
      "train avg_loss is:  0.12373531609773636\n",
      "val avg_loss is:  0.09868671000003815\n",
      "  -> Best model saved! (epoch 35, val_loss: 0.0987)\n",
      "\n",
      "\n",
      "Running EPOCH 36\n",
      "train avg_loss is:  0.12190310657024384\n",
      "val avg_loss is:  0.0999530479311943\n",
      "\n",
      "\n",
      "Running EPOCH 37\n",
      "train avg_loss is:  0.12055995315313339\n",
      "val avg_loss is:  0.09646239876747131\n",
      "  -> Best model saved! (epoch 37, val_loss: 0.0965)\n",
      "\n",
      "\n",
      "Running EPOCH 38\n",
      "train avg_loss is:  0.12314411252737045\n",
      "val avg_loss is:  0.09720714390277863\n",
      "\n",
      "\n",
      "Running EPOCH 39\n",
      "train avg_loss is:  0.11973404139280319\n",
      "val avg_loss is:  0.09650345146656036\n",
      "\n",
      "\n",
      "Running EPOCH 40\n",
      "train avg_loss is:  0.11681487411260605\n",
      "val avg_loss is:  0.0969700962305069\n",
      "\n",
      "\n",
      "Running EPOCH 41\n",
      "train avg_loss is:  0.1180034801363945\n",
      "val avg_loss is:  0.09501423686742783\n",
      "  -> Best model saved! (epoch 41, val_loss: 0.0950)\n",
      "\n",
      "\n",
      "Running EPOCH 42\n",
      "train avg_loss is:  0.1143268570303917\n",
      "val avg_loss is:  0.09560307115316391\n",
      "\n",
      "\n",
      "Running EPOCH 43\n",
      "train avg_loss is:  0.11362174898386002\n",
      "val avg_loss is:  0.09344393014907837\n",
      "  -> Best model saved! (epoch 43, val_loss: 0.0934)\n",
      "\n",
      "\n",
      "Running EPOCH 44\n",
      "train avg_loss is:  0.11396291851997375\n",
      "val avg_loss is:  0.09559782594442368\n",
      "\n",
      "\n",
      "Running EPOCH 45\n",
      "train avg_loss is:  0.11214606463909149\n",
      "val avg_loss is:  0.0934506505727768\n",
      "\n",
      "\n",
      "Running EPOCH 46\n",
      "train avg_loss is:  0.11270532011985779\n",
      "val avg_loss is:  0.09135967493057251\n",
      "  -> Best model saved! (epoch 46, val_loss: 0.0914)\n",
      "\n",
      "\n",
      "Running EPOCH 47\n",
      "train avg_loss is:  0.10969750583171844\n",
      "val avg_loss is:  0.0915171355009079\n",
      "\n",
      "\n",
      "Running EPOCH 48\n",
      "train avg_loss is:  0.11310483515262604\n",
      "val avg_loss is:  0.09316237270832062\n",
      "\n",
      "\n",
      "Running EPOCH 49\n",
      "train avg_loss is:  0.11127398908138275\n",
      "val avg_loss is:  0.09296996891498566\n",
      "\n",
      "\n",
      "Running EPOCH 50\n",
      "train avg_loss is:  0.11008863896131516\n",
      "val avg_loss is:  0.09024076163768768\n",
      "  -> Best model saved! (epoch 50, val_loss: 0.0902)\n",
      "\n",
      "\n",
      "Loading best model from checkpoint: results/SGD/selectivity/Kd/S(1uM)_label/v1/fold2/best_model.pt\n",
      "Best model loaded: epoch 50, val_loss: 0.0902\n",
      "Running EPOCH 1\n",
      "weight loss is:  0.14254316687583923\n",
      "Running EPOCH 2\n",
      "weight loss is:  0.14254078269004822\n",
      "Running EPOCH 3\n",
      "weight loss is:  0.14253860712051392\n",
      "Running EPOCH 4\n",
      "weight loss is:  0.14253664016723633\n",
      "Running EPOCH 5\n",
      "weight loss is:  0.14253485202789307\n",
      "Running EPOCH 6\n",
      "weight loss is:  0.14253325760364532\n",
      "Running EPOCH 7\n",
      "weight loss is:  0.1425318717956543\n",
      "Running EPOCH 8\n",
      "weight loss is:  0.1425306648015976\n",
      "Running EPOCH 9\n",
      "weight loss is:  0.14252962172031403\n",
      "Running EPOCH 10\n",
      "weight loss is:  0.14252878725528717\n",
      "Running EPOCH 11\n",
      "weight loss is:  0.14252811670303345\n",
      "Running EPOCH 12\n",
      "weight loss is:  0.14252762496471405\n",
      "Running EPOCH 13\n",
      "weight loss is:  0.14252731204032898\n",
      "Running EPOCH 14\n",
      "weight loss is:  0.14252716302871704\n",
      "Running EPOCH 15\n",
      "weight loss is:  0.14252720773220062\n",
      "Running EPOCH 16\n",
      "weight loss is:  0.14252738654613495\n",
      "Running EPOCH 17\n",
      "weight loss is:  0.14252778887748718\n",
      "Running EPOCH 18\n",
      "weight loss is:  0.14252831041812897\n",
      "Running EPOCH 19\n",
      "weight loss is:  0.14252902567386627\n",
      "Running EPOCH 20\n",
      "weight loss is:  0.14252988994121552\n",
      "Running EPOCH 21\n",
      "weight loss is:  0.1425309181213379\n",
      "Running EPOCH 22\n",
      "weight loss is:  0.1425320953130722\n",
      "Running EPOCH 23\n",
      "weight loss is:  0.14253343641757965\n",
      "Running EPOCH 24\n",
      "weight loss is:  0.14253491163253784\n",
      "Running EPOCH 25\n",
      "weight loss is:  0.14253656566143036\n",
      "Running EPOCH 26\n",
      "weight loss is:  0.142538383603096\n",
      "Running EPOCH 27\n",
      "weight loss is:  0.1425403207540512\n",
      "Running EPOCH 28\n",
      "weight loss is:  0.14254242181777954\n",
      "Running EPOCH 29\n",
      "weight loss is:  0.14254465699195862\n",
      "Running EPOCH 30\n",
      "weight loss is:  0.14254704117774963\n",
      "Running EPOCH 31\n",
      "weight loss is:  0.1425495445728302\n",
      "Running EPOCH 32\n",
      "weight loss is:  0.1425522267818451\n",
      "Running EPOCH 33\n",
      "weight loss is:  0.14255502820014954\n",
      "Running EPOCH 34\n",
      "weight loss is:  0.14255796372890472\n",
      "Running EPOCH 35\n",
      "weight loss is:  0.14256104826927185\n",
      "Running EPOCH 36\n",
      "weight loss is:  0.14256422221660614\n",
      "Running EPOCH 37\n",
      "weight loss is:  0.14256757497787476\n",
      "Running EPOCH 38\n",
      "weight loss is:  0.14257103204727173\n",
      "Running EPOCH 39\n",
      "weight loss is:  0.14257463812828064\n",
      "Running EPOCH 40\n",
      "weight loss is:  0.1425783336162567\n",
      "Running EPOCH 41\n",
      "weight loss is:  0.14258219301700592\n",
      "Running EPOCH 42\n",
      "weight loss is:  0.1425861418247223\n",
      "Running EPOCH 43\n",
      "weight loss is:  0.1425902545452118\n",
      "Running EPOCH 44\n",
      "weight loss is:  0.14259444177150726\n",
      "Running EPOCH 45\n",
      "weight loss is:  0.14259874820709229\n",
      "Running EPOCH 46\n",
      "weight loss is:  0.14260320365428925\n",
      "Running EPOCH 47\n",
      "weight loss is:  0.14260773360729218\n",
      "Running EPOCH 48\n",
      "weight loss is:  0.14261239767074585\n",
      "Running EPOCH 49\n",
      "weight loss is:  0.14261718094348907\n",
      "Running EPOCH 50\n",
      "weight loss is:  0.14262205362319946\n",
      "\n",
      "\n",
      "{1: np.float32(0.6627012), 2: np.float32(0.19623873), 3: np.float32(0.14428054)}\n",
      "Fold 2 Metrics:\n",
      "  ACC: 0.8829\n",
      "  F1: 0.9347\n",
      "  AUC: 0.7897\n",
      "  Precision: 0.8774\n",
      "  Recall: 1.0000\n",
      "\n",
      "\n",
      "Fold 2 completed!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Processing Fold 3\n",
      "============================================================\n",
      "Loading datasets for selectivity Kd fold 3\n",
      "Train samples: 400\n",
      "Validation samples: 45\n",
      "Test samples: 111\n",
      "============================================================\n",
      "Running EPOCH 1\n",
      "train avg_loss is:  0.22197139263153076\n",
      "val avg_loss is:  0.197841614484787\n",
      "  -> Best model saved! (epoch 1, val_loss: 0.1978)\n",
      "\n",
      "\n",
      "Running EPOCH 2\n",
      "train avg_loss is:  0.20808909833431244\n",
      "val avg_loss is:  0.18159207701683044\n",
      "  -> Best model saved! (epoch 2, val_loss: 0.1816)\n",
      "\n",
      "\n",
      "Running EPOCH 3\n",
      "train avg_loss is:  0.20014309883117676\n",
      "val avg_loss is:  0.1700485646724701\n",
      "  -> Best model saved! (epoch 3, val_loss: 0.1700)\n",
      "\n",
      "\n",
      "Running EPOCH 4\n",
      "train avg_loss is:  0.19583185017108917\n",
      "val avg_loss is:  0.16129577159881592\n",
      "  -> Best model saved! (epoch 4, val_loss: 0.1613)\n",
      "\n",
      "\n",
      "Running EPOCH 5\n",
      "train avg_loss is:  0.1922435462474823\n",
      "val avg_loss is:  0.1552588939666748\n",
      "  -> Best model saved! (epoch 5, val_loss: 0.1553)\n",
      "\n",
      "\n",
      "Running EPOCH 6\n",
      "train avg_loss is:  0.18948151171207428\n",
      "val avg_loss is:  0.14966928958892822\n",
      "  -> Best model saved! (epoch 6, val_loss: 0.1497)\n",
      "\n",
      "\n",
      "Running EPOCH 7\n",
      "train avg_loss is:  0.18739566206932068\n",
      "val avg_loss is:  0.14642003178596497\n",
      "  -> Best model saved! (epoch 7, val_loss: 0.1464)\n",
      "\n",
      "\n",
      "Running EPOCH 8\n",
      "train avg_loss is:  0.18185986578464508\n",
      "val avg_loss is:  0.14364926517009735\n",
      "  -> Best model saved! (epoch 8, val_loss: 0.1436)\n",
      "\n",
      "\n",
      "Running EPOCH 9\n",
      "train avg_loss is:  0.18115197122097015\n",
      "val avg_loss is:  0.14135180413722992\n",
      "  -> Best model saved! (epoch 9, val_loss: 0.1414)\n",
      "\n",
      "\n",
      "Running EPOCH 10\n",
      "train avg_loss is:  0.17779606580734253\n",
      "val avg_loss is:  0.1388465166091919\n",
      "  -> Best model saved! (epoch 10, val_loss: 0.1388)\n",
      "\n",
      "\n",
      "Running EPOCH 11\n",
      "train avg_loss is:  0.17533747851848602\n",
      "val avg_loss is:  0.1380317658185959\n",
      "  -> Best model saved! (epoch 11, val_loss: 0.1380)\n",
      "\n",
      "\n",
      "Running EPOCH 12\n",
      "train avg_loss is:  0.17313343286514282\n",
      "val avg_loss is:  0.13573536276817322\n",
      "  -> Best model saved! (epoch 12, val_loss: 0.1357)\n",
      "\n",
      "\n",
      "Running EPOCH 13\n",
      "train avg_loss is:  0.16745051741600037\n",
      "val avg_loss is:  0.13291095197200775\n",
      "  -> Best model saved! (epoch 13, val_loss: 0.1329)\n",
      "\n",
      "\n",
      "Running EPOCH 14\n",
      "train avg_loss is:  0.16407573223114014\n",
      "val avg_loss is:  0.12862204015254974\n",
      "  -> Best model saved! (epoch 14, val_loss: 0.1286)\n",
      "\n",
      "\n",
      "Running EPOCH 15\n",
      "train avg_loss is:  0.16326093673706055\n",
      "val avg_loss is:  0.12393852323293686\n",
      "  -> Best model saved! (epoch 15, val_loss: 0.1239)\n",
      "\n",
      "\n",
      "Running EPOCH 16\n",
      "train avg_loss is:  0.16190283000469208\n",
      "val avg_loss is:  0.11932295560836792\n",
      "  -> Best model saved! (epoch 16, val_loss: 0.1193)\n",
      "\n",
      "\n",
      "Running EPOCH 17\n",
      "train avg_loss is:  0.16031718254089355\n",
      "val avg_loss is:  0.11540558189153671\n",
      "  -> Best model saved! (epoch 17, val_loss: 0.1154)\n",
      "\n",
      "\n",
      "Running EPOCH 18\n",
      "train avg_loss is:  0.15361513197422028\n",
      "val avg_loss is:  0.11163051426410675\n",
      "  -> Best model saved! (epoch 18, val_loss: 0.1116)\n",
      "\n",
      "\n",
      "Running EPOCH 19\n",
      "train avg_loss is:  0.1523537039756775\n",
      "val avg_loss is:  0.10827700793743134\n",
      "  -> Best model saved! (epoch 19, val_loss: 0.1083)\n",
      "\n",
      "\n",
      "Running EPOCH 20\n",
      "train avg_loss is:  0.15010365843772888\n",
      "val avg_loss is:  0.10570041835308075\n",
      "  -> Best model saved! (epoch 20, val_loss: 0.1057)\n",
      "\n",
      "\n",
      "Running EPOCH 21\n",
      "train avg_loss is:  0.14852234721183777\n",
      "val avg_loss is:  0.10203303396701813\n",
      "  -> Best model saved! (epoch 21, val_loss: 0.1020)\n",
      "\n",
      "\n",
      "Running EPOCH 22\n",
      "train avg_loss is:  0.15157383680343628\n",
      "val avg_loss is:  0.09843447804450989\n",
      "  -> Best model saved! (epoch 22, val_loss: 0.0984)\n",
      "\n",
      "\n",
      "Running EPOCH 23\n",
      "train avg_loss is:  0.14695365726947784\n",
      "val avg_loss is:  0.09653210639953613\n",
      "  -> Best model saved! (epoch 23, val_loss: 0.0965)\n",
      "\n",
      "\n",
      "Running EPOCH 24\n",
      "train avg_loss is:  0.14418083429336548\n",
      "val avg_loss is:  0.09407508373260498\n",
      "  -> Best model saved! (epoch 24, val_loss: 0.0941)\n",
      "\n",
      "\n",
      "Running EPOCH 25\n",
      "train avg_loss is:  0.14488902688026428\n",
      "val avg_loss is:  0.09254692494869232\n",
      "  -> Best model saved! (epoch 25, val_loss: 0.0925)\n",
      "\n",
      "\n",
      "Running EPOCH 26\n",
      "train avg_loss is:  0.13874216377735138\n",
      "val avg_loss is:  0.09024368226528168\n",
      "  -> Best model saved! (epoch 26, val_loss: 0.0902)\n",
      "\n",
      "\n",
      "Running EPOCH 27\n",
      "train avg_loss is:  0.14156624674797058\n",
      "val avg_loss is:  0.08881812542676926\n",
      "  -> Best model saved! (epoch 27, val_loss: 0.0888)\n",
      "\n",
      "\n",
      "Running EPOCH 28\n",
      "train avg_loss is:  0.13927575945854187\n",
      "val avg_loss is:  0.08834041655063629\n",
      "  -> Best model saved! (epoch 28, val_loss: 0.0883)\n",
      "\n",
      "\n",
      "Running EPOCH 29\n",
      "train avg_loss is:  0.13694670796394348\n",
      "val avg_loss is:  0.08713486790657043\n",
      "  -> Best model saved! (epoch 29, val_loss: 0.0871)\n",
      "\n",
      "\n",
      "Running EPOCH 30\n",
      "train avg_loss is:  0.13545772433280945\n",
      "val avg_loss is:  0.08587472885847092\n",
      "  -> Best model saved! (epoch 30, val_loss: 0.0859)\n",
      "\n",
      "\n",
      "Running EPOCH 31\n",
      "train avg_loss is:  0.12940585613250732\n",
      "val avg_loss is:  0.08365675061941147\n",
      "  -> Best model saved! (epoch 31, val_loss: 0.0837)\n",
      "\n",
      "\n",
      "Running EPOCH 32\n",
      "train avg_loss is:  0.13440781831741333\n",
      "val avg_loss is:  0.08146416395902634\n",
      "  -> Best model saved! (epoch 32, val_loss: 0.0815)\n",
      "\n",
      "\n",
      "Running EPOCH 33\n",
      "train avg_loss is:  0.13176009058952332\n",
      "val avg_loss is:  0.08085609972476959\n",
      "  -> Best model saved! (epoch 33, val_loss: 0.0809)\n",
      "\n",
      "\n",
      "Running EPOCH 34\n",
      "train avg_loss is:  0.12831377983093262\n",
      "val avg_loss is:  0.08011436462402344\n",
      "  -> Best model saved! (epoch 34, val_loss: 0.0801)\n",
      "\n",
      "\n",
      "Running EPOCH 35\n",
      "train avg_loss is:  0.1274704933166504\n",
      "val avg_loss is:  0.08058299124240875\n",
      "\n",
      "\n",
      "Running EPOCH 36\n",
      "train avg_loss is:  0.1310158371925354\n",
      "val avg_loss is:  0.07878744602203369\n",
      "  -> Best model saved! (epoch 36, val_loss: 0.0788)\n",
      "\n",
      "\n",
      "Running EPOCH 37\n",
      "train avg_loss is:  0.13035139441490173\n",
      "val avg_loss is:  0.07795586436986923\n",
      "  -> Best model saved! (epoch 37, val_loss: 0.0780)\n",
      "\n",
      "\n",
      "Running EPOCH 38\n",
      "train avg_loss is:  0.13037556409835815\n",
      "val avg_loss is:  0.07762929052114487\n",
      "  -> Best model saved! (epoch 38, val_loss: 0.0776)\n",
      "\n",
      "\n",
      "Running EPOCH 39\n",
      "train avg_loss is:  0.127481147646904\n",
      "val avg_loss is:  0.07815173268318176\n",
      "\n",
      "\n",
      "Running EPOCH 40\n",
      "train avg_loss is:  0.1250125765800476\n",
      "val avg_loss is:  0.0768614187836647\n",
      "  -> Best model saved! (epoch 40, val_loss: 0.0769)\n",
      "\n",
      "\n",
      "Running EPOCH 41\n",
      "train avg_loss is:  0.1250247359275818\n",
      "val avg_loss is:  0.07598405331373215\n",
      "  -> Best model saved! (epoch 41, val_loss: 0.0760)\n",
      "\n",
      "\n",
      "Running EPOCH 42\n",
      "train avg_loss is:  0.11993502825498581\n",
      "val avg_loss is:  0.07480012625455856\n",
      "  -> Best model saved! (epoch 42, val_loss: 0.0748)\n",
      "\n",
      "\n",
      "Running EPOCH 43\n",
      "train avg_loss is:  0.122226282954216\n",
      "val avg_loss is:  0.07461696863174438\n",
      "  -> Best model saved! (epoch 43, val_loss: 0.0746)\n",
      "\n",
      "\n",
      "Running EPOCH 44\n",
      "train avg_loss is:  0.11993345618247986\n",
      "val avg_loss is:  0.07344670593738556\n",
      "  -> Best model saved! (epoch 44, val_loss: 0.0734)\n",
      "\n",
      "\n",
      "Running EPOCH 45\n",
      "train avg_loss is:  0.1211511418223381\n",
      "val avg_loss is:  0.07572980225086212\n",
      "\n",
      "\n",
      "Running EPOCH 46\n",
      "train avg_loss is:  0.12068299949169159\n",
      "val avg_loss is:  0.07555416226387024\n",
      "\n",
      "\n",
      "Running EPOCH 47\n",
      "train avg_loss is:  0.12036450207233429\n",
      "val avg_loss is:  0.07223427295684814\n",
      "  -> Best model saved! (epoch 47, val_loss: 0.0722)\n",
      "\n",
      "\n",
      "Running EPOCH 48\n",
      "train avg_loss is:  0.12276364117860794\n",
      "val avg_loss is:  0.07235497236251831\n",
      "\n",
      "\n",
      "Running EPOCH 49\n",
      "train avg_loss is:  0.12037864327430725\n",
      "val avg_loss is:  0.06961830705404282\n",
      "  -> Best model saved! (epoch 49, val_loss: 0.0696)\n",
      "\n",
      "\n",
      "Running EPOCH 50\n",
      "train avg_loss is:  0.11988576501607895\n",
      "val avg_loss is:  0.07021448761224747\n",
      "\n",
      "\n",
      "Loading best model from checkpoint: results/SGD/selectivity/Kd/S(1uM)_label/v1/fold3/best_model.pt\n",
      "Best model loaded: epoch 49, val_loss: 0.0696\n",
      "Running EPOCH 1\n",
      "weight loss is:  0.11533955484628677\n",
      "Running EPOCH 2\n",
      "weight loss is:  0.11537187546491623\n",
      "Running EPOCH 3\n",
      "weight loss is:  0.11540424078702927\n",
      "Running EPOCH 4\n",
      "weight loss is:  0.11543664336204529\n",
      "Running EPOCH 5\n",
      "weight loss is:  0.11546912044286728\n",
      "Running EPOCH 6\n",
      "weight loss is:  0.11550164967775345\n",
      "Running EPOCH 7\n",
      "weight loss is:  0.11553427577018738\n",
      "Running EPOCH 8\n",
      "weight loss is:  0.1155669167637825\n",
      "Running EPOCH 9\n",
      "weight loss is:  0.1155996173620224\n",
      "Running EPOCH 10\n",
      "weight loss is:  0.11563237756490707\n",
      "Running EPOCH 11\n",
      "weight loss is:  0.11566516011953354\n",
      "Running EPOCH 12\n",
      "weight loss is:  0.11569802463054657\n",
      "Running EPOCH 13\n",
      "weight loss is:  0.1157309040427208\n",
      "Running EPOCH 14\n",
      "weight loss is:  0.11576385051012039\n",
      "Running EPOCH 15\n",
      "weight loss is:  0.11579681187868118\n",
      "Running EPOCH 16\n",
      "weight loss is:  0.11582985520362854\n",
      "Running EPOCH 17\n",
      "weight loss is:  0.1158628910779953\n",
      "Running EPOCH 18\n",
      "weight loss is:  0.11589597165584564\n",
      "Running EPOCH 19\n",
      "weight loss is:  0.11592907458543777\n",
      "Running EPOCH 20\n",
      "weight loss is:  0.11596222221851349\n",
      "Running EPOCH 21\n",
      "weight loss is:  0.11599542200565338\n",
      "Running EPOCH 22\n",
      "weight loss is:  0.11602859944105148\n",
      "Running EPOCH 23\n",
      "weight loss is:  0.11606185138225555\n",
      "Running EPOCH 24\n",
      "weight loss is:  0.11609511077404022\n",
      "Running EPOCH 25\n",
      "weight loss is:  0.11612838506698608\n",
      "Running EPOCH 26\n",
      "weight loss is:  0.11616168916225433\n",
      "Running EPOCH 27\n",
      "weight loss is:  0.11619500070810318\n",
      "Running EPOCH 28\n",
      "weight loss is:  0.11622831970453262\n",
      "Running EPOCH 29\n",
      "weight loss is:  0.11626168340444565\n",
      "Running EPOCH 30\n",
      "weight loss is:  0.11629503220319748\n",
      "Running EPOCH 31\n",
      "weight loss is:  0.11632843315601349\n",
      "Running EPOCH 32\n",
      "weight loss is:  0.1163618341088295\n",
      "Running EPOCH 33\n",
      "weight loss is:  0.11639521270990372\n",
      "Running EPOCH 34\n",
      "weight loss is:  0.11642861366271973\n",
      "Running EPOCH 35\n",
      "weight loss is:  0.11646201461553574\n",
      "Running EPOCH 36\n",
      "weight loss is:  0.11649542301893234\n",
      "Running EPOCH 37\n",
      "weight loss is:  0.11652885377407074\n",
      "Running EPOCH 38\n",
      "weight loss is:  0.11656226217746735\n",
      "Running EPOCH 39\n",
      "weight loss is:  0.11659567058086395\n",
      "Running EPOCH 40\n",
      "weight loss is:  0.11662909388542175\n",
      "Running EPOCH 41\n",
      "weight loss is:  0.11666248738765717\n",
      "Running EPOCH 42\n",
      "weight loss is:  0.11669589579105377\n",
      "Running EPOCH 43\n",
      "weight loss is:  0.11672929674386978\n",
      "Running EPOCH 44\n",
      "weight loss is:  0.116762675344944\n",
      "Running EPOCH 45\n",
      "weight loss is:  0.11679606884717941\n",
      "Running EPOCH 46\n",
      "weight loss is:  0.11682941764593124\n",
      "Running EPOCH 47\n",
      "weight loss is:  0.11686278879642487\n",
      "Running EPOCH 48\n",
      "weight loss is:  0.1168961226940155\n",
      "Running EPOCH 49\n",
      "weight loss is:  0.11692944169044495\n",
      "Running EPOCH 50\n",
      "weight loss is:  0.11696276068687439\n",
      "\n",
      "\n",
      "{1: np.float32(0.65040445), 2: np.float32(0.20043033), 3: np.float32(0.15373841)}\n",
      "Fold 3 Metrics:\n",
      "  ACC: 0.9279\n",
      "  F1: 0.9596\n",
      "  AUC: 0.9028\n",
      "  Precision: 0.9314\n",
      "  Recall: 0.9896\n",
      "\n",
      "\n",
      "Fold 3 completed!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Processing Fold 4\n",
      "============================================================\n",
      "Loading datasets for selectivity Kd fold 4\n",
      "Train samples: 400\n",
      "Validation samples: 45\n",
      "Test samples: 111\n",
      "============================================================\n",
      "Running EPOCH 1\n",
      "train avg_loss is:  0.215872123837471\n",
      "val avg_loss is:  0.19704443216323853\n",
      "  -> Best model saved! (epoch 1, val_loss: 0.1970)\n",
      "\n",
      "\n",
      "Running EPOCH 2\n",
      "train avg_loss is:  0.20076902210712433\n",
      "val avg_loss is:  0.18286749720573425\n",
      "  -> Best model saved! (epoch 2, val_loss: 0.1829)\n",
      "\n",
      "\n",
      "Running EPOCH 3\n",
      "train avg_loss is:  0.18963417410850525\n",
      "val avg_loss is:  0.17015230655670166\n",
      "  -> Best model saved! (epoch 3, val_loss: 0.1702)\n",
      "\n",
      "\n",
      "Running EPOCH 4\n",
      "train avg_loss is:  0.18033438920974731\n",
      "val avg_loss is:  0.163417249917984\n",
      "  -> Best model saved! (epoch 4, val_loss: 0.1634)\n",
      "\n",
      "\n",
      "Running EPOCH 5\n",
      "train avg_loss is:  0.17977294325828552\n",
      "val avg_loss is:  0.15547426044940948\n",
      "  -> Best model saved! (epoch 5, val_loss: 0.1555)\n",
      "\n",
      "\n",
      "Running EPOCH 6\n",
      "train avg_loss is:  0.1738889068365097\n",
      "val avg_loss is:  0.1505681872367859\n",
      "  -> Best model saved! (epoch 6, val_loss: 0.1506)\n",
      "\n",
      "\n",
      "Running EPOCH 7\n",
      "train avg_loss is:  0.1747041940689087\n",
      "val avg_loss is:  0.14831075072288513\n",
      "  -> Best model saved! (epoch 7, val_loss: 0.1483)\n",
      "\n",
      "\n",
      "Running EPOCH 8\n",
      "train avg_loss is:  0.16862741112709045\n",
      "val avg_loss is:  0.14599864184856415\n",
      "  -> Best model saved! (epoch 8, val_loss: 0.1460)\n",
      "\n",
      "\n",
      "Running EPOCH 9\n",
      "train avg_loss is:  0.1673862189054489\n",
      "val avg_loss is:  0.14293527603149414\n",
      "  -> Best model saved! (epoch 9, val_loss: 0.1429)\n",
      "\n",
      "\n",
      "Running EPOCH 10\n",
      "train avg_loss is:  0.1650567352771759\n",
      "val avg_loss is:  0.14145322144031525\n",
      "  -> Best model saved! (epoch 10, val_loss: 0.1415)\n",
      "\n",
      "\n",
      "Running EPOCH 11\n",
      "train avg_loss is:  0.16029894351959229\n",
      "val avg_loss is:  0.13990992307662964\n",
      "  -> Best model saved! (epoch 11, val_loss: 0.1399)\n",
      "\n",
      "\n",
      "Running EPOCH 12\n",
      "train avg_loss is:  0.16176021099090576\n",
      "val avg_loss is:  0.13785788416862488\n",
      "  -> Best model saved! (epoch 12, val_loss: 0.1379)\n",
      "\n",
      "\n",
      "Running EPOCH 13\n",
      "train avg_loss is:  0.15734192728996277\n",
      "val avg_loss is:  0.13637788593769073\n",
      "  -> Best model saved! (epoch 13, val_loss: 0.1364)\n",
      "\n",
      "\n",
      "Running EPOCH 14\n",
      "train avg_loss is:  0.15526123344898224\n",
      "val avg_loss is:  0.1339157074689865\n",
      "  -> Best model saved! (epoch 14, val_loss: 0.1339)\n",
      "\n",
      "\n",
      "Running EPOCH 15\n",
      "train avg_loss is:  0.15373548865318298\n",
      "val avg_loss is:  0.13215970993041992\n",
      "  -> Best model saved! (epoch 15, val_loss: 0.1322)\n",
      "\n",
      "\n",
      "Running EPOCH 16\n",
      "train avg_loss is:  0.15009647607803345\n",
      "val avg_loss is:  0.12905362248420715\n",
      "  -> Best model saved! (epoch 16, val_loss: 0.1291)\n",
      "\n",
      "\n",
      "Running EPOCH 17\n",
      "train avg_loss is:  0.14822356402873993\n",
      "val avg_loss is:  0.1263287365436554\n",
      "  -> Best model saved! (epoch 17, val_loss: 0.1263)\n",
      "\n",
      "\n",
      "Running EPOCH 18\n",
      "train avg_loss is:  0.14588001370429993\n",
      "val avg_loss is:  0.12389897555112839\n",
      "  -> Best model saved! (epoch 18, val_loss: 0.1239)\n",
      "\n",
      "\n",
      "Running EPOCH 19\n",
      "train avg_loss is:  0.14242568612098694\n",
      "val avg_loss is:  0.12362883985042572\n",
      "  -> Best model saved! (epoch 19, val_loss: 0.1236)\n",
      "\n",
      "\n",
      "Running EPOCH 20\n",
      "train avg_loss is:  0.13980859518051147\n",
      "val avg_loss is:  0.1186370700597763\n",
      "  -> Best model saved! (epoch 20, val_loss: 0.1186)\n",
      "\n",
      "\n",
      "Running EPOCH 21\n",
      "train avg_loss is:  0.143462672829628\n",
      "val avg_loss is:  0.1199222207069397\n",
      "\n",
      "\n",
      "Running EPOCH 22\n",
      "train avg_loss is:  0.1396052986383438\n",
      "val avg_loss is:  0.11864586174488068\n",
      "\n",
      "\n",
      "Running EPOCH 23\n",
      "train avg_loss is:  0.1353914886713028\n",
      "val avg_loss is:  0.11689937114715576\n",
      "  -> Best model saved! (epoch 23, val_loss: 0.1169)\n",
      "\n",
      "\n",
      "Running EPOCH 24\n",
      "train avg_loss is:  0.14060746133327484\n",
      "val avg_loss is:  0.11464351415634155\n",
      "  -> Best model saved! (epoch 24, val_loss: 0.1146)\n",
      "\n",
      "\n",
      "Running EPOCH 25\n",
      "train avg_loss is:  0.13516342639923096\n",
      "val avg_loss is:  0.11207039654254913\n",
      "  -> Best model saved! (epoch 25, val_loss: 0.1121)\n",
      "\n",
      "\n",
      "Running EPOCH 26\n",
      "train avg_loss is:  0.13396021723747253\n",
      "val avg_loss is:  0.11334836483001709\n",
      "\n",
      "\n",
      "Running EPOCH 27\n",
      "train avg_loss is:  0.13054603338241577\n",
      "val avg_loss is:  0.11113870143890381\n",
      "  -> Best model saved! (epoch 27, val_loss: 0.1111)\n",
      "\n",
      "\n",
      "Running EPOCH 28\n",
      "train avg_loss is:  0.13080208003520966\n",
      "val avg_loss is:  0.11070950329303741\n",
      "  -> Best model saved! (epoch 28, val_loss: 0.1107)\n",
      "\n",
      "\n",
      "Running EPOCH 29\n",
      "train avg_loss is:  0.12879136204719543\n",
      "val avg_loss is:  0.10870066285133362\n",
      "  -> Best model saved! (epoch 29, val_loss: 0.1087)\n",
      "\n",
      "\n",
      "Running EPOCH 30\n",
      "train avg_loss is:  0.1293450891971588\n",
      "val avg_loss is:  0.10885857045650482\n",
      "\n",
      "\n",
      "Running EPOCH 31\n",
      "train avg_loss is:  0.1251237392425537\n",
      "val avg_loss is:  0.10511581599712372\n",
      "  -> Best model saved! (epoch 31, val_loss: 0.1051)\n",
      "\n",
      "\n",
      "Running EPOCH 32\n",
      "train avg_loss is:  0.12406183034181595\n",
      "val avg_loss is:  0.1051064059138298\n",
      "  -> Best model saved! (epoch 32, val_loss: 0.1051)\n",
      "\n",
      "\n",
      "Running EPOCH 33\n",
      "train avg_loss is:  0.12342311441898346\n",
      "val avg_loss is:  0.1044807881116867\n",
      "  -> Best model saved! (epoch 33, val_loss: 0.1045)\n",
      "\n",
      "\n",
      "Running EPOCH 34\n",
      "train avg_loss is:  0.12136532366275787\n",
      "val avg_loss is:  0.10411011427640915\n",
      "  -> Best model saved! (epoch 34, val_loss: 0.1041)\n",
      "\n",
      "\n",
      "Running EPOCH 35\n",
      "train avg_loss is:  0.1176086887717247\n",
      "val avg_loss is:  0.10302093625068665\n",
      "  -> Best model saved! (epoch 35, val_loss: 0.1030)\n",
      "\n",
      "\n",
      "Running EPOCH 36\n",
      "train avg_loss is:  0.124662846326828\n",
      "val avg_loss is:  0.1014898344874382\n",
      "  -> Best model saved! (epoch 36, val_loss: 0.1015)\n",
      "\n",
      "\n",
      "Running EPOCH 37\n",
      "train avg_loss is:  0.12004336714744568\n",
      "val avg_loss is:  0.10161440074443817\n",
      "\n",
      "\n",
      "Running EPOCH 38\n",
      "train avg_loss is:  0.11879436671733856\n",
      "val avg_loss is:  0.10428114980459213\n",
      "\n",
      "\n",
      "Running EPOCH 39\n",
      "train avg_loss is:  0.12037757784128189\n",
      "val avg_loss is:  0.10064582526683807\n",
      "  -> Best model saved! (epoch 39, val_loss: 0.1006)\n",
      "\n",
      "\n",
      "Running EPOCH 40\n",
      "train avg_loss is:  0.11763917654752731\n",
      "val avg_loss is:  0.09928720444440842\n",
      "  -> Best model saved! (epoch 40, val_loss: 0.0993)\n",
      "\n",
      "\n",
      "Running EPOCH 41\n",
      "train avg_loss is:  0.12140436470508575\n",
      "val avg_loss is:  0.09956955164670944\n",
      "\n",
      "\n",
      "Running EPOCH 42\n",
      "train avg_loss is:  0.1145133227109909\n",
      "val avg_loss is:  0.10036512464284897\n",
      "\n",
      "\n",
      "Running EPOCH 43\n",
      "train avg_loss is:  0.11440802365541458\n",
      "val avg_loss is:  0.0982975885272026\n",
      "  -> Best model saved! (epoch 43, val_loss: 0.0983)\n",
      "\n",
      "\n",
      "Running EPOCH 44\n",
      "train avg_loss is:  0.11318519711494446\n",
      "val avg_loss is:  0.09781605005264282\n",
      "  -> Best model saved! (epoch 44, val_loss: 0.0978)\n",
      "\n",
      "\n",
      "Running EPOCH 45\n",
      "train avg_loss is:  0.11362119019031525\n",
      "val avg_loss is:  0.10077466815710068\n",
      "\n",
      "\n",
      "Running EPOCH 46\n",
      "train avg_loss is:  0.11571551859378815\n",
      "val avg_loss is:  0.09500213712453842\n",
      "  -> Best model saved! (epoch 46, val_loss: 0.0950)\n",
      "\n",
      "\n",
      "Running EPOCH 47\n",
      "train avg_loss is:  0.11537998914718628\n",
      "val avg_loss is:  0.0952984020113945\n",
      "\n",
      "\n",
      "Running EPOCH 48\n",
      "train avg_loss is:  0.11397095024585724\n",
      "val avg_loss is:  0.09478671848773956\n",
      "  -> Best model saved! (epoch 48, val_loss: 0.0948)\n",
      "\n",
      "\n",
      "Running EPOCH 49\n",
      "train avg_loss is:  0.11255735158920288\n",
      "val avg_loss is:  0.09563545882701874\n",
      "\n",
      "\n",
      "Running EPOCH 50\n",
      "train avg_loss is:  0.11160529404878616\n",
      "val avg_loss is:  0.09476117789745331\n",
      "  -> Best model saved! (epoch 50, val_loss: 0.0948)\n",
      "\n",
      "\n",
      "Loading best model from checkpoint: results/SGD/selectivity/Kd/S(1uM)_label/v1/fold4/best_model.pt\n",
      "Best model loaded: epoch 50, val_loss: 0.0948\n",
      "Running EPOCH 1\n",
      "weight loss is:  0.22764825820922852\n",
      "Running EPOCH 2\n",
      "weight loss is:  0.22757644951343536\n",
      "Running EPOCH 3\n",
      "weight loss is:  0.22750520706176758\n",
      "Running EPOCH 4\n",
      "weight loss is:  0.22743448615074158\n",
      "Running EPOCH 5\n",
      "weight loss is:  0.22736427187919617\n",
      "Running EPOCH 6\n",
      "weight loss is:  0.22729454934597015\n",
      "Running EPOCH 7\n",
      "weight loss is:  0.2272253781557083\n",
      "Running EPOCH 8\n",
      "weight loss is:  0.22715668380260468\n",
      "Running EPOCH 9\n",
      "weight loss is:  0.22708849608898163\n",
      "Running EPOCH 10\n",
      "weight loss is:  0.22702081501483917\n",
      "Running EPOCH 11\n",
      "weight loss is:  0.2269536405801773\n",
      "Running EPOCH 12\n",
      "weight loss is:  0.22688692808151245\n",
      "Running EPOCH 13\n",
      "weight loss is:  0.22682072222232819\n",
      "Running EPOCH 14\n",
      "weight loss is:  0.2267550379037857\n",
      "Running EPOCH 15\n",
      "weight loss is:  0.22668978571891785\n",
      "Running EPOCH 16\n",
      "weight loss is:  0.22662506997585297\n",
      "Running EPOCH 17\n",
      "weight loss is:  0.2265607863664627\n",
      "Running EPOCH 18\n",
      "weight loss is:  0.22649699449539185\n",
      "Running EPOCH 19\n",
      "weight loss is:  0.2264336794614792\n",
      "Running EPOCH 20\n",
      "weight loss is:  0.22637084126472473\n",
      "Running EPOCH 21\n",
      "weight loss is:  0.2263084501028061\n",
      "Running EPOCH 22\n",
      "weight loss is:  0.22624653577804565\n",
      "Running EPOCH 23\n",
      "weight loss is:  0.22618506848812103\n",
      "Running EPOCH 24\n",
      "weight loss is:  0.2261240929365158\n",
      "Running EPOCH 25\n",
      "weight loss is:  0.2260635644197464\n",
      "Running EPOCH 26\n",
      "weight loss is:  0.2260034680366516\n",
      "Running EPOCH 27\n",
      "weight loss is:  0.22594381868839264\n",
      "Running EPOCH 28\n",
      "weight loss is:  0.2258845865726471\n",
      "Running EPOCH 29\n",
      "weight loss is:  0.22582586109638214\n",
      "Running EPOCH 30\n",
      "weight loss is:  0.22576753795146942\n",
      "Running EPOCH 31\n",
      "weight loss is:  0.22570964694023132\n",
      "Running EPOCH 32\n",
      "weight loss is:  0.22565218806266785\n",
      "Running EPOCH 33\n",
      "weight loss is:  0.22559522092342377\n",
      "Running EPOCH 34\n",
      "weight loss is:  0.22553864121437073\n",
      "Running EPOCH 35\n",
      "weight loss is:  0.22548246383666992\n",
      "Running EPOCH 36\n",
      "weight loss is:  0.22542671859264374\n",
      "Running EPOCH 37\n",
      "weight loss is:  0.22537140548229218\n",
      "Running EPOCH 38\n",
      "weight loss is:  0.22531649470329285\n",
      "Running EPOCH 39\n",
      "weight loss is:  0.22526203095912933\n",
      "Running EPOCH 40\n",
      "weight loss is:  0.22520795464515686\n",
      "Running EPOCH 41\n",
      "weight loss is:  0.22515429556369781\n",
      "Running EPOCH 42\n",
      "weight loss is:  0.2251010239124298\n",
      "Running EPOCH 43\n",
      "weight loss is:  0.22504816949367523\n",
      "Running EPOCH 44\n",
      "weight loss is:  0.2249957174062729\n",
      "Running EPOCH 45\n",
      "weight loss is:  0.22494366765022278\n",
      "Running EPOCH 46\n",
      "weight loss is:  0.2248920053243637\n",
      "Running EPOCH 47\n",
      "weight loss is:  0.22484074532985687\n",
      "Running EPOCH 48\n",
      "weight loss is:  0.22478985786437988\n",
      "Running EPOCH 49\n",
      "weight loss is:  0.22473937273025513\n",
      "Running EPOCH 50\n",
      "weight loss is:  0.2246892750263214\n",
      "\n",
      "\n",
      "{1: np.float32(0.6484454), 2: np.float32(0.20423794), 3: np.float32(0.15000287)}\n",
      "Fold 4 Metrics:\n",
      "  ACC: 0.8829\n",
      "  F1: 0.9360\n",
      "  AUC: 0.7680\n",
      "  Precision: 0.8962\n",
      "  Recall: 0.9794\n",
      "\n",
      "\n",
      "Fold 4 completed!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Processing Fold 5\n",
      "============================================================\n",
      "Loading datasets for selectivity Kd fold 5\n",
      "Train samples: 400\n",
      "Validation samples: 45\n",
      "Test samples: 111\n",
      "============================================================\n",
      "Running EPOCH 1\n",
      "train avg_loss is:  0.2535668909549713\n",
      "val avg_loss is:  0.2426736205816269\n",
      "  -> Best model saved! (epoch 1, val_loss: 0.2427)\n",
      "\n",
      "\n",
      "Running EPOCH 2\n",
      "train avg_loss is:  0.236210435628891\n",
      "val avg_loss is:  0.2262820303440094\n",
      "  -> Best model saved! (epoch 2, val_loss: 0.2263)\n",
      "\n",
      "\n",
      "Running EPOCH 3\n",
      "train avg_loss is:  0.22385069727897644\n",
      "val avg_loss is:  0.21396347880363464\n",
      "  -> Best model saved! (epoch 3, val_loss: 0.2140)\n",
      "\n",
      "\n",
      "Running EPOCH 4\n",
      "train avg_loss is:  0.21659019589424133\n",
      "val avg_loss is:  0.20288792252540588\n",
      "  -> Best model saved! (epoch 4, val_loss: 0.2029)\n",
      "\n",
      "\n",
      "Running EPOCH 5\n",
      "train avg_loss is:  0.21060457825660706\n",
      "val avg_loss is:  0.19728398323059082\n",
      "  -> Best model saved! (epoch 5, val_loss: 0.1973)\n",
      "\n",
      "\n",
      "Running EPOCH 6\n",
      "train avg_loss is:  0.20577962696552277\n",
      "val avg_loss is:  0.19245611131191254\n",
      "  -> Best model saved! (epoch 6, val_loss: 0.1925)\n",
      "\n",
      "\n",
      "Running EPOCH 7\n",
      "train avg_loss is:  0.20255152881145477\n",
      "val avg_loss is:  0.18915121257305145\n",
      "  -> Best model saved! (epoch 7, val_loss: 0.1892)\n",
      "\n",
      "\n",
      "Running EPOCH 8\n",
      "train avg_loss is:  0.19779559969902039\n",
      "val avg_loss is:  0.18246600031852722\n",
      "  -> Best model saved! (epoch 8, val_loss: 0.1825)\n",
      "\n",
      "\n",
      "Running EPOCH 9\n",
      "train avg_loss is:  0.19617168605327606\n",
      "val avg_loss is:  0.17799341678619385\n",
      "  -> Best model saved! (epoch 9, val_loss: 0.1780)\n",
      "\n",
      "\n",
      "Running EPOCH 10\n",
      "train avg_loss is:  0.18938098847866058\n",
      "val avg_loss is:  0.17315760254859924\n",
      "  -> Best model saved! (epoch 10, val_loss: 0.1732)\n",
      "\n",
      "\n",
      "Running EPOCH 11\n",
      "train avg_loss is:  0.18834295868873596\n",
      "val avg_loss is:  0.17089149355888367\n",
      "  -> Best model saved! (epoch 11, val_loss: 0.1709)\n",
      "\n",
      "\n",
      "Running EPOCH 12\n",
      "train avg_loss is:  0.18475554883480072\n",
      "val avg_loss is:  0.1664653718471527\n",
      "  -> Best model saved! (epoch 12, val_loss: 0.1665)\n",
      "\n",
      "\n",
      "Running EPOCH 13\n",
      "train avg_loss is:  0.18229582905769348\n",
      "val avg_loss is:  0.16347995400428772\n",
      "  -> Best model saved! (epoch 13, val_loss: 0.1635)\n",
      "\n",
      "\n",
      "Running EPOCH 14\n",
      "train avg_loss is:  0.17830748856067657\n",
      "val avg_loss is:  0.15895597636699677\n",
      "  -> Best model saved! (epoch 14, val_loss: 0.1590)\n",
      "\n",
      "\n",
      "Running EPOCH 15\n",
      "train avg_loss is:  0.17658568918704987\n",
      "val avg_loss is:  0.15586908161640167\n",
      "  -> Best model saved! (epoch 15, val_loss: 0.1559)\n",
      "\n",
      "\n",
      "Running EPOCH 16\n",
      "train avg_loss is:  0.1731623411178589\n",
      "val avg_loss is:  0.15210846066474915\n",
      "  -> Best model saved! (epoch 16, val_loss: 0.1521)\n",
      "\n",
      "\n",
      "Running EPOCH 17\n",
      "train avg_loss is:  0.16856326162815094\n",
      "val avg_loss is:  0.15029311180114746\n",
      "  -> Best model saved! (epoch 17, val_loss: 0.1503)\n",
      "\n",
      "\n",
      "Running EPOCH 18\n",
      "train avg_loss is:  0.16514964401721954\n",
      "val avg_loss is:  0.14740677177906036\n",
      "  -> Best model saved! (epoch 18, val_loss: 0.1474)\n",
      "\n",
      "\n",
      "Running EPOCH 19\n",
      "train avg_loss is:  0.16219213604927063\n",
      "val avg_loss is:  0.14298999309539795\n",
      "  -> Best model saved! (epoch 19, val_loss: 0.1430)\n",
      "\n",
      "\n",
      "Running EPOCH 20\n",
      "train avg_loss is:  0.1588342785835266\n",
      "val avg_loss is:  0.13820534944534302\n",
      "  -> Best model saved! (epoch 20, val_loss: 0.1382)\n",
      "\n",
      "\n",
      "Running EPOCH 21\n",
      "train avg_loss is:  0.15706980228424072\n",
      "val avg_loss is:  0.13580551743507385\n",
      "  -> Best model saved! (epoch 21, val_loss: 0.1358)\n",
      "\n",
      "\n",
      "Running EPOCH 22\n",
      "train avg_loss is:  0.15498308837413788\n",
      "val avg_loss is:  0.13262586295604706\n",
      "  -> Best model saved! (epoch 22, val_loss: 0.1326)\n",
      "\n",
      "\n",
      "Running EPOCH 23\n",
      "train avg_loss is:  0.14928850531578064\n",
      "val avg_loss is:  0.1312294900417328\n",
      "  -> Best model saved! (epoch 23, val_loss: 0.1312)\n",
      "\n",
      "\n",
      "Running EPOCH 24\n",
      "train avg_loss is:  0.14899593591690063\n",
      "val avg_loss is:  0.12715652585029602\n",
      "  -> Best model saved! (epoch 24, val_loss: 0.1272)\n",
      "\n",
      "\n",
      "Running EPOCH 25\n",
      "train avg_loss is:  0.14752629399299622\n",
      "val avg_loss is:  0.1261293739080429\n",
      "  -> Best model saved! (epoch 25, val_loss: 0.1261)\n",
      "\n",
      "\n",
      "Running EPOCH 26\n",
      "train avg_loss is:  0.14381638169288635\n",
      "val avg_loss is:  0.12403780221939087\n",
      "  -> Best model saved! (epoch 26, val_loss: 0.1240)\n",
      "\n",
      "\n",
      "Running EPOCH 27\n",
      "train avg_loss is:  0.1436036229133606\n",
      "val avg_loss is:  0.1212247908115387\n",
      "  -> Best model saved! (epoch 27, val_loss: 0.1212)\n",
      "\n",
      "\n",
      "Running EPOCH 28\n",
      "train avg_loss is:  0.14178383350372314\n",
      "val avg_loss is:  0.11819159239530563\n",
      "  -> Best model saved! (epoch 28, val_loss: 0.1182)\n",
      "\n",
      "\n",
      "Running EPOCH 29\n",
      "train avg_loss is:  0.13757061958312988\n",
      "val avg_loss is:  0.1170513927936554\n",
      "  -> Best model saved! (epoch 29, val_loss: 0.1171)\n",
      "\n",
      "\n",
      "Running EPOCH 30\n",
      "train avg_loss is:  0.13499917089939117\n",
      "val avg_loss is:  0.11730443686246872\n",
      "\n",
      "\n",
      "Running EPOCH 31\n",
      "train avg_loss is:  0.13407398760318756\n",
      "val avg_loss is:  0.11345317214727402\n",
      "  -> Best model saved! (epoch 31, val_loss: 0.1135)\n",
      "\n",
      "\n",
      "Running EPOCH 32\n",
      "train avg_loss is:  0.13193310797214508\n",
      "val avg_loss is:  0.11310096085071564\n",
      "  -> Best model saved! (epoch 32, val_loss: 0.1131)\n",
      "\n",
      "\n",
      "Running EPOCH 33\n",
      "train avg_loss is:  0.12956148386001587\n",
      "val avg_loss is:  0.10997780412435532\n",
      "  -> Best model saved! (epoch 33, val_loss: 0.1100)\n",
      "\n",
      "\n",
      "Running EPOCH 34\n",
      "train avg_loss is:  0.13225212693214417\n",
      "val avg_loss is:  0.10902039706707001\n",
      "  -> Best model saved! (epoch 34, val_loss: 0.1090)\n",
      "\n",
      "\n",
      "Running EPOCH 35\n",
      "train avg_loss is:  0.12891170382499695\n",
      "val avg_loss is:  0.10741531103849411\n",
      "  -> Best model saved! (epoch 35, val_loss: 0.1074)\n",
      "\n",
      "\n",
      "Running EPOCH 36\n",
      "train avg_loss is:  0.12829257547855377\n",
      "val avg_loss is:  0.10697653144598007\n",
      "  -> Best model saved! (epoch 36, val_loss: 0.1070)\n",
      "\n",
      "\n",
      "Running EPOCH 37\n",
      "train avg_loss is:  0.12748661637306213\n",
      "val avg_loss is:  0.10875988006591797\n",
      "\n",
      "\n",
      "Running EPOCH 38\n",
      "train avg_loss is:  0.12336447089910507\n",
      "val avg_loss is:  0.10583250224590302\n",
      "  -> Best model saved! (epoch 38, val_loss: 0.1058)\n",
      "\n",
      "\n",
      "Running EPOCH 39\n",
      "train avg_loss is:  0.12479522079229355\n",
      "val avg_loss is:  0.10596629232168198\n",
      "\n",
      "\n",
      "Running EPOCH 40\n",
      "train avg_loss is:  0.12618857622146606\n",
      "val avg_loss is:  0.10409202426671982\n",
      "  -> Best model saved! (epoch 40, val_loss: 0.1041)\n",
      "\n",
      "\n",
      "Running EPOCH 41\n",
      "train avg_loss is:  0.12033966928720474\n",
      "val avg_loss is:  0.1054045781493187\n",
      "\n",
      "\n",
      "Running EPOCH 42\n",
      "train avg_loss is:  0.12118406593799591\n",
      "val avg_loss is:  0.10644638538360596\n",
      "\n",
      "\n",
      "Running EPOCH 43\n",
      "train avg_loss is:  0.11799626052379608\n",
      "val avg_loss is:  0.10448391735553741\n",
      "\n",
      "\n",
      "Running EPOCH 44\n",
      "train avg_loss is:  0.12176213413476944\n",
      "val avg_loss is:  0.10315694659948349\n",
      "  -> Best model saved! (epoch 44, val_loss: 0.1032)\n",
      "\n",
      "\n",
      "Running EPOCH 45\n",
      "train avg_loss is:  0.1196984201669693\n",
      "val avg_loss is:  0.10245627164840698\n",
      "  -> Best model saved! (epoch 45, val_loss: 0.1025)\n",
      "\n",
      "\n",
      "Running EPOCH 46\n",
      "train avg_loss is:  0.11862371861934662\n",
      "val avg_loss is:  0.10294774174690247\n",
      "\n",
      "\n",
      "Running EPOCH 47\n",
      "train avg_loss is:  0.11870663613080978\n",
      "val avg_loss is:  0.10425706952810287\n",
      "\n",
      "\n",
      "Running EPOCH 48\n",
      "train avg_loss is:  0.11596237123012543\n",
      "val avg_loss is:  0.10215684026479721\n",
      "  -> Best model saved! (epoch 48, val_loss: 0.1022)\n",
      "\n",
      "\n",
      "Running EPOCH 49\n",
      "train avg_loss is:  0.11670759320259094\n",
      "val avg_loss is:  0.10297463834285736\n",
      "\n",
      "\n",
      "Running EPOCH 50\n",
      "train avg_loss is:  0.11429549008607864\n",
      "val avg_loss is:  0.10215899348258972\n",
      "\n",
      "\n",
      "Loading best model from checkpoint: results/SGD/selectivity/Kd/S(1uM)_label/v1/fold5/best_model.pt\n",
      "Best model loaded: epoch 48, val_loss: 0.1022\n",
      "Running EPOCH 1\n",
      "weight loss is:  0.21352055668830872\n",
      "Running EPOCH 2\n",
      "weight loss is:  0.21349483728408813\n",
      "Running EPOCH 3\n",
      "weight loss is:  0.21346944570541382\n",
      "Running EPOCH 4\n",
      "weight loss is:  0.21344435214996338\n",
      "Running EPOCH 5\n",
      "weight loss is:  0.21341955661773682\n",
      "Running EPOCH 6\n",
      "weight loss is:  0.21339508891105652\n",
      "Running EPOCH 7\n",
      "weight loss is:  0.2133709192276001\n",
      "Running EPOCH 8\n",
      "weight loss is:  0.21334703266620636\n",
      "Running EPOCH 9\n",
      "weight loss is:  0.2133234739303589\n",
      "Running EPOCH 10\n",
      "weight loss is:  0.2133001834154129\n",
      "Running EPOCH 11\n",
      "weight loss is:  0.213277205824852\n",
      "Running EPOCH 12\n",
      "weight loss is:  0.21325451135635376\n",
      "Running EPOCH 13\n",
      "weight loss is:  0.2132321298122406\n",
      "Running EPOCH 14\n",
      "weight loss is:  0.21320998668670654\n",
      "Running EPOCH 15\n",
      "weight loss is:  0.21318817138671875\n",
      "Running EPOCH 16\n",
      "weight loss is:  0.21316660940647125\n",
      "Running EPOCH 17\n",
      "weight loss is:  0.21314534544944763\n",
      "Running EPOCH 18\n",
      "weight loss is:  0.2131243497133255\n",
      "Running EPOCH 19\n",
      "weight loss is:  0.21310362219810486\n",
      "Running EPOCH 20\n",
      "weight loss is:  0.2130831629037857\n",
      "Running EPOCH 21\n",
      "weight loss is:  0.21306298673152924\n",
      "Running EPOCH 22\n",
      "weight loss is:  0.21304309368133545\n",
      "Running EPOCH 23\n",
      "weight loss is:  0.21302342414855957\n",
      "Running EPOCH 24\n",
      "weight loss is:  0.21300405263900757\n",
      "Running EPOCH 25\n",
      "weight loss is:  0.21298493444919586\n",
      "Running EPOCH 26\n",
      "weight loss is:  0.21296606957912445\n",
      "Running EPOCH 27\n",
      "weight loss is:  0.21294747292995453\n",
      "Running EPOCH 28\n",
      "weight loss is:  0.2129291146993637\n",
      "Running EPOCH 29\n",
      "weight loss is:  0.21291102468967438\n",
      "Running EPOCH 30\n",
      "weight loss is:  0.21289317309856415\n",
      "Running EPOCH 31\n",
      "weight loss is:  0.2128755897283554\n",
      "Running EPOCH 32\n",
      "weight loss is:  0.2128582000732422\n",
      "Running EPOCH 33\n",
      "weight loss is:  0.21284110844135284\n",
      "Running EPOCH 34\n",
      "weight loss is:  0.2128242403268814\n",
      "Running EPOCH 35\n",
      "weight loss is:  0.21280759572982788\n",
      "Running EPOCH 36\n",
      "weight loss is:  0.21279118955135345\n",
      "Running EPOCH 37\n",
      "weight loss is:  0.2127750664949417\n",
      "Running EPOCH 38\n",
      "weight loss is:  0.2127591222524643\n",
      "Running EPOCH 39\n",
      "weight loss is:  0.21274343132972717\n",
      "Running EPOCH 40\n",
      "weight loss is:  0.21272797882556915\n",
      "Running EPOCH 41\n",
      "weight loss is:  0.21271273493766785\n",
      "Running EPOCH 42\n",
      "weight loss is:  0.21269772946834564\n",
      "Running EPOCH 43\n",
      "weight loss is:  0.21268294751644135\n",
      "Running EPOCH 44\n",
      "weight loss is:  0.21266835927963257\n",
      "Running EPOCH 45\n",
      "weight loss is:  0.21265403926372528\n",
      "Running EPOCH 46\n",
      "weight loss is:  0.21263988316059113\n",
      "Running EPOCH 47\n",
      "weight loss is:  0.21262595057487488\n",
      "Running EPOCH 48\n",
      "weight loss is:  0.21261224150657654\n",
      "Running EPOCH 49\n",
      "weight loss is:  0.2125987708568573\n",
      "Running EPOCH 50\n",
      "weight loss is:  0.21258544921875\n",
      "\n",
      "\n",
      "{1: np.float32(0.6606338), 2: np.float32(0.20035268), 3: np.float32(0.14157529)}\n",
      "Fold 5 Metrics:\n",
      "  ACC: 0.9369\n",
      "  F1: 0.9665\n",
      "  AUC: 0.8376\n",
      "  Precision: 0.9352\n",
      "  Recall: 1.0000\n",
      "\n",
      "\n",
      "Fold 5 completed!\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "All folds completed!\n",
      "============================================================\n",
      "\n",
      "Summary metrics saved: ./results/SGD/selectivity/Kd/S(1uM)_label/v1/summary_metric.csv\n",
      "\n",
      "Summary Metrics (Test Set):\n",
      "   metric     mean      std\n",
      "      acc 0.901126 0.028935\n",
      "       f1 0.945486 0.016336\n",
      "      auc 0.821367 0.052197\n",
      "precision 0.903729 0.028025\n",
      "   recall 0.991688 0.008645\n"
     ]
    }
   ],
   "source": [
    "all_fold_metrics = []\n",
    "\n",
    "for fold_num in range(start_fold, end_fold + 1):\n",
    "    # print('\\n' + '=' * 60)\n",
    "    # print(f'Processing Fold {fold_num}')\n",
    "    # print('=' * 60)\n",
    "    \n",
    "    # Fold setting\n",
    "    label = f'{dataset_name}_{target_col}_fold{fold_num}'\n",
    "    \n",
    "    resultLoss = {'losses_train': [], 'losses_val': []}\n",
    "    \n",
    "    # dataset path\n",
    "    data_dir = f'./data/{dataset_name}/{target_col}/fold{fold_num}'\n",
    "    \n",
    "    # Load dataset\n",
    "    print(f'Loading datasets for {dataset_name} {target_col} fold {fold_num}')\n",
    "    train_data = formDataset_Single(root=data_dir, dataset=f'train')\n",
    "    val_data = formDataset_Single(root=data_dir, dataset=f'val')\n",
    "    test_data = formDataset_Single(root=data_dir, dataset=f'test')\n",
    "    \n",
    "    # Calculate max index from datasets to set vocab size dynamically\n",
    "    max_idx = 0\n",
    "    max_smi_len = 0\n",
    "    \n",
    "    for data in train_data:\n",
    "        max_idx = max(max_idx, data.smi.max().item())\n",
    "        max_smi_len = max(max_smi_len, data.smi.shape[1])\n",
    "    \n",
    "    if len(val_data) > 0:\n",
    "        for data in val_data:\n",
    "            max_idx = max(max_idx, data.smi.max().item())\n",
    "            max_smi_len = max(max_smi_len, data.smi.shape[1])\n",
    "            \n",
    "    if len(test_data) > 0:\n",
    "        for data in test_data:\n",
    "            max_idx = max(max_idx, data.smi.max().item())\n",
    "            max_smi_len = max(max_smi_len, data.smi.shape[1])\n",
    "    vocab_size = max_idx + 1\n",
    "    \n",
    "    print(f'Detected max token index: {max_idx}. Setting vocab_size to: {vocab_size}')\n",
    "    print(f'Detected max sequence length: {max_smi_len}. Setting num_features_smi to: {max_smi_len}')\n",
    "    \n",
    "    # : vocab_size num_features_smi  \n",
    "    argsCom['vocab_size'] = vocab_size      #  \n",
    "    argsCom['num_features_smi'] = max_smi_len # Linear  ( )\n",
    "        \n",
    "    result_dir = os.path.join('results', 'SGD', dataset_name, target_col, version, f'fold{fold_num}')\n",
    "    os.makedirs(result_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate DataLoader\n",
    "    trainLoader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    valLoader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "    testLoader = DataLoader(test_data, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "    \n",
    "    # print(f'Train samples: {len(train_data)}')\n",
    "    # print(f'Validation samples: {len(val_data)}')\n",
    "    # print(f'Test samples: {len(test_data)}')\n",
    "    # print('=' * 60)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    learning_rate = 0.0001\n",
    "    com_model = comModel(argsCom).to(device)\n",
    "    optimizer_com = torch.optim.Adam(com_model.parameters(), lr=learning_rate)\n",
    "    criterion_com = torch.nn.BCEWithLogitsLoss() \n",
    "\n",
    "    com_model.train()\n",
    "    for i in range(epochs):\n",
    "        print(\"Running EPOCH\", i+1)\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        '''\n",
    "            train\n",
    "        '''\n",
    "        for batch_idx, data in enumerate(trainLoader):\n",
    "            encodedSmi = torch.LongTensor(data.smi).to(device)\n",
    "            encodedSmi_mask = torch.LongTensor(getInput_mask(data.smi)).to(device)\n",
    "            ecfp = torch.FloatTensor(data.ep).to(device)\n",
    "            y = data.y.to(device)\n",
    "            x = data.x.to(device)\n",
    "            edge_index = data.edge_index.to(device)\n",
    "            batch = data.batch.to(device)\n",
    "            \n",
    "            y_norm = y.float().to(device)              \n",
    "            \n",
    "            y_pred = com_model(encodedSmi, encodedSmi_mask, ecfp, x, edge_index, batch)\n",
    "            \n",
    "            loss1 = criterion_com(y_pred[0], y_norm)\n",
    "            loss2 = criterion_com(y_pred[1], y_norm)\n",
    "            loss3 = criterion_com(y_pred[2], y_norm)\n",
    "            loss = (loss1 + loss2 + loss3) / 3\n",
    "            total_loss += (loss.data)/3\n",
    "            optimizer_com.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(com_model.parameters(),0.5)\n",
    "            optimizer_com.step()\n",
    "            n_batches+=1\n",
    "            torch.cuda.empty_cache()\n",
    "        avg_loss = total_loss / n_batches\n",
    "        resultLoss['losses_train'].append(avg_loss)\n",
    "        print('train avg_loss is: ', avg_loss.item())\n",
    "\n",
    "        '''\n",
    "            val\n",
    "        '''\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        for batch_idx, data in enumerate(valLoader):\n",
    "            encodedSmi = torch.LongTensor(data.smi).to(device)\n",
    "            encodedSmi_mask = torch.LongTensor(getInput_mask(data.smi)).to(device)\n",
    "            ecfp = torch.FloatTensor(data.ep).to(device)\n",
    "            y = data.y.to(device)\n",
    "            x = data.x.to(device)\n",
    "            edge_index = data.edge_index.to(device)\n",
    "            batch = data.batch.to(device)\n",
    "            \n",
    "\n",
    "            y_norm = y.float().to(device)       \n",
    "            \n",
    "            y_pred = com_model(encodedSmi, encodedSmi_mask, ecfp, x, edge_index, batch)\n",
    "            \n",
    "            loss1 = criterion_com(y_pred[0], y_norm)\n",
    "            loss2 = criterion_com(y_pred[1], y_norm)\n",
    "            loss3 = criterion_com(y_pred[2], y_norm)\n",
    "            loss = (loss1 + loss2 + loss3) / 3\n",
    "            \n",
    "            total_loss += (loss.data)/3\n",
    "            \n",
    "            n_batches+=1\n",
    "            \n",
    "        avg_loss = total_loss / n_batches\n",
    "        resultLoss['losses_val'].append(avg_loss)\n",
    "        val_loss_value = avg_loss.item()\n",
    "        print('val avg_loss is: ', val_loss_value)\n",
    "        \n",
    "        # save best model checkpoint\n",
    "        if val_loss_value < best_val_loss:\n",
    "            best_val_loss = val_loss_value\n",
    "            best_epoch = i + 1\n",
    "            # remove before best checkpoint\n",
    "            best_checkpoint_path = os.path.join(result_dir, 'best_model.pt')\n",
    "            if os.path.exists(best_checkpoint_path):\n",
    "                os.remove(best_checkpoint_path)\n",
    "            # save new best checkpoint\n",
    "            torch.save({\n",
    "                'epoch': best_epoch,\n",
    "                'model_state_dict': com_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer_com.state_dict(),\n",
    "                'val_loss': best_val_loss,\n",
    "                'argsCom': argsCom\n",
    "            }, best_checkpoint_path)\n",
    "            print(f'  -> Best model saved! (epoch {best_epoch}, val_loss: {best_val_loss:.4f})')\n",
    "        print('\\n')\n",
    "\n",
    "    # load best checkpoint\n",
    "    best_checkpoint_path = os.path.join(result_dir, 'best_model.pt')\n",
    "    if os.path.exists(best_checkpoint_path):\n",
    "        print(f'Loading best model from checkpoint: {best_checkpoint_path}')\n",
    "        checkpoint = torch.load(best_checkpoint_path, map_location=device, weights_only=False)\n",
    "        com_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        # update best epoch\n",
    "        best_epoch = checkpoint['epoch']\n",
    "        best_val_loss = checkpoint['val_loss']\n",
    "        print(f'Best model loaded: epoch {best_epoch}, val_loss: {best_val_loss:.4f}')\n",
    "    else:\n",
    "        print(f'Warning: Best checkpoint not found, using last epoch model')\n",
    "    \n",
    "    val_data = []\n",
    "    pred_data1 = []\n",
    "    pred_data2 = []\n",
    "    pred_data3 = []\n",
    "    com_model.eval()\n",
    "    for batch_idx, data in enumerate(valLoader):\n",
    "        encodedSmi = torch.LongTensor(data.smi).to(device)\n",
    "        encodedSmi_mask = torch.LongTensor(getInput_mask(data.smi)).to(device)\n",
    "        ecfp = torch.FloatTensor(data.ep).to(device)\n",
    "        y = data.y.to(device)\n",
    "        x = data.x.to(device)\n",
    "        edge_index = data.edge_index.to(device)\n",
    "        batch = data.batch.to(device)\n",
    "        \n",
    "\n",
    "        y_norm = y.float().to(device)               # []\n",
    "        \n",
    "        y_pred = com_model(encodedSmi, encodedSmi_mask, ecfp, x, edge_index, batch)\n",
    "        val_data.append(y_norm.cpu().tolist())\n",
    "        pred_data1.append(y_pred[0].tolist())\n",
    "        pred_data2.append(y_pred[1].tolist())\n",
    "        pred_data3.append(y_pred[2].tolist()) \n",
    "\n",
    "    def flattened_data(data):\n",
    "        fla_data = [item for sublist in data for item in sublist]\n",
    "        merged_data = np.array(fla_data).flatten() \n",
    "        return merged_data\n",
    "    \n",
    "    data_ = {}\n",
    "    data_['pred1'] = flattened_data(pred_data1)\n",
    "    data_['pred2'] = flattened_data(pred_data2)\n",
    "    data_['pred3'] = flattened_data(pred_data3)\n",
    "    data_['true'] = flattened_data(val_data)\n",
    "\n",
    "    val_data_flat = flattened_data(val_data).astype(np.float32)\n",
    "    pred_data1_flat = flattened_data(pred_data1).astype(np.float32)\n",
    "    pred_data2_flat = flattened_data(pred_data2).astype(np.float32)\n",
    "    pred_data3_flat = flattened_data(pred_data3).astype(np.float32)\n",
    "\n",
    "    learning_rate_weight = 0.01\n",
    "    weights = torch.tensor([0.7, 0.2, 0.1], requires_grad=True, dtype=torch.float)\n",
    "    optimizer_weight = torch.optim.SGD([weights], lr=learning_rate_weight)\n",
    "    criterion_weight = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    val_data_tensor = torch.from_numpy(val_data_flat)\n",
    "    pred_data1_tensor = torch.from_numpy(pred_data1_flat)\n",
    "    pred_data2_tensor = torch.from_numpy(pred_data2_flat)\n",
    "    pred_data3_tensor = torch.from_numpy(pred_data3_flat)\n",
    "    for i in range(epochs):\n",
    "        print(\"Running EPOCH\", i+1)\n",
    "        if weights.data.sum() > 1:\n",
    "            weights.data /= weights.data.sum()\n",
    "        # Compute weighted_output using torch operations, not .detach().numpy()\n",
    "        weighted_output = (weights[0] * pred_data1_tensor + weights[1] * pred_data2_tensor + weights[2] * pred_data3_tensor).to(device)\n",
    "        val_output = val_data_tensor.to(device)\n",
    "        loss = criterion_weight(weighted_output, val_output)\n",
    "        optimizer_weight.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_weight.step()\n",
    "        print('weight loss is: ', loss.item())\n",
    "    print('\\n')\n",
    "\n",
    "    numpy_weights = weights.detach().numpy()\n",
    "    weightDic = {}\n",
    "    weightDic[1] = numpy_weights[0]\n",
    "    weightDic[2] = numpy_weights[1]\n",
    "    weightDic[3] = numpy_weights[2]\n",
    "    print(weightDic)\n",
    "\n",
    "    sour_data = []\n",
    "    pred_data1 = []\n",
    "    pred_data2 = []\n",
    "    pred_data3 = []\n",
    "\n",
    "    com_model.eval()\n",
    "    for batch_idx, data in enumerate(testLoader):\n",
    "        encodedSmi = torch.LongTensor(data.smi).to(device)\n",
    "        encodedSmi_mask = torch.LongTensor(getInput_mask(data.smi)).to(device)\n",
    "        ecfp = torch.FloatTensor(data.ep).to(device)\n",
    "        y = data.y.to(device)\n",
    "        x = data.x.to(device)\n",
    "        edge_index = data.edge_index.to(device)\n",
    "        batch = data.batch.to(device)\n",
    "        \n",
    "        y_norm = y.float().to(device)        \n",
    "        \n",
    "        y_pred = com_model(encodedSmi, encodedSmi_mask, ecfp, x, edge_index, batch)\n",
    "\n",
    "        sour_data.append(y_norm.cpu().tolist())\n",
    "        pred_data1.append(y_pred[0].tolist())\n",
    "        pred_data2.append(y_pred[1].tolist())\n",
    "        pred_data3.append(y_pred[2].tolist()) \n",
    "        \n",
    "    yPred_logits = numpy_weights[0] * flattened_data(pred_data1) + numpy_weights[1] * flattened_data(pred_data2) + numpy_weights[2] * flattened_data(pred_data3)\n",
    "    ySour = flattened_data(sour_data)\n",
    "    \n",
    "    if len(yPred_logits) == 0 or len(ySour) == 0:\n",
    "        print(f'Warning: Empty predictions or targets. yPred length={len(yPred_logits)}, ySour length={len(ySour)}')\n",
    "        print(f'Skipping result saving for fold {fold_num}')\n",
    "        continue\n",
    "    \n",
    "    if len(yPred_logits) != len(ySour):\n",
    "        min_len = min(len(yPred_logits), len(ySour))\n",
    "        print(f'Warning: Length mismatch. yPred length={len(yPred_logits)}, ySour length={len(ySour)}. Truncating to min length.')\n",
    "        yPred_logits = yPred_logits[:min_len]\n",
    "        ySour = ySour[:min_len]\n",
    "    \n",
    "    yPred_prob = 1 / (1 + np.exp(-yPred_logits)) \n",
    "    yPred_class = (yPred_prob >= 0.5).astype(int)\n",
    "    ySour_class = ySour.astype(int)\n",
    "\n",
    "    acc = accuracy_score(ySour_class, yPred_class)\n",
    "    f1 = f1_score(ySour_class, yPred_class)\n",
    "    try:\n",
    "        auc = roc_auc_score(ySour_class, yPred_prob)\n",
    "    except ValueError:\n",
    "        auc = 0.0\n",
    "    precision = precision_score(ySour_class, yPred_class, zero_division=0)\n",
    "    recall = recall_score(ySour_class, yPred_class, zero_division=0)\n",
    "\n",
    "    fold_metrics = {\n",
    "        'fold': fold_num,\n",
    "        'acc': acc,\n",
    "        'f1': f1,\n",
    "        'auc': auc,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "    all_fold_metrics.append(fold_metrics)\n",
    "    \n",
    "    print(f'Fold {fold_num} Metrics:')\n",
    "    print(f'  ACC: {acc:.4f}')\n",
    "    print(f'  F1: {f1:.4f}')\n",
    "    print(f'  AUC: {auc:.4f}')\n",
    "    print(f'  Precision: {precision:.4f}')\n",
    "    print(f'  Recall: {recall:.4f}')\n",
    "    print('\\n')\n",
    "    \n",
    "    # Save results\n",
    "    savePath = f'{result_dir}/{label}_weight_epoch_{best_epoch}.csv'\n",
    "    df_weight = pd.DataFrame(weightDic.items(), columns=['Key', 'Value'])\n",
    "    df_weight.to_csv(savePath, index=False)\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        'y_true': ySour_class,\n",
    "        'y_pred_prob': yPred_prob,\n",
    "        'y_pred_class': yPred_class\n",
    "    })\n",
    "    predictions_path = f'{result_dir}/predictions.csv'\n",
    "    predictions_df.to_csv(predictions_path, index=False)\n",
    "    \n",
    "    metric_df = pd.DataFrame([fold_metrics])\n",
    "    metric_path = f'{result_dir}/metric.csv'\n",
    "    metric_df.to_csv(metric_path, index=False)\n",
    "    \n",
    "    savePath = f'{result_dir}/{label}_validation_epoch_{best_epoch}_data.csv'\n",
    "    data_as_lists = {key: data_[key].tolist() for key in data_}\n",
    "    df_data = pd.DataFrame(data_as_lists)\n",
    "    df_data.to_csv(savePath, index=False)\n",
    "    \n",
    "    print(f'Fold {fold_num} completed!')\n",
    "    print('=' * 60)\n",
    "\n",
    "print('\\n' + '=' * 60)\n",
    "print('All folds completed!')\n",
    "print('=' * 60)\n",
    "\n",
    "\n",
    "if len(all_fold_metrics) > 0:\n",
    "    all_metrics_df = pd.DataFrame(all_fold_metrics)\n",
    "    summary_metrics = {\n",
    "        'metric': ['acc', 'f1', 'auc', 'precision', 'recall'],\n",
    "        'mean': [\n",
    "            all_metrics_df['acc'].mean(),\n",
    "            all_metrics_df['f1'].mean(),\n",
    "            all_metrics_df['auc'].mean(),\n",
    "            all_metrics_df['precision'].mean(),\n",
    "            all_metrics_df['recall'].mean()\n",
    "        ],\n",
    "        'std': [\n",
    "            all_metrics_df['acc'].std(),\n",
    "            all_metrics_df['f1'].std(),\n",
    "            all_metrics_df['auc'].std(),\n",
    "            all_metrics_df['precision'].std(),\n",
    "            all_metrics_df['recall'].std()\n",
    "        ]\n",
    "    }\n",
    "    summary_df = pd.DataFrame(summary_metrics)\n",
    "    summary_dir = f'./results/SGD/{dataset_name}/{target_col}/{version}'\n",
    "    os.makedirs(summary_dir, exist_ok=True)\n",
    "    summary_path = f'{summary_dir}/summary_metric.csv'\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    print(f'\\nSummary metrics saved: {summary_path}')\n",
    "    print('\\nSummary Metrics (Test Set):')\n",
    "    print(summary_df.to_string(index=False))\n",
    "    \n",
    "    all_metrics_path = f'{summary_dir}/all_folds_metrics.csv'\n",
    "    all_metrics_df.to_csv(all_metrics_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
